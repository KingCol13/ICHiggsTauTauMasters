{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tree loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Task 2\n",
    "\n",
    "#This is a script for testing for neutrinos reconstruction\n",
    "\n",
    "import sys\n",
    "#sys.path.append(\"/eos/home-a/acraplet/.local/lib/python2.7/site-packages\")\n",
    "sys.path.append(\"/home/acraplet/Alie/Masters/ICHiggsTauTauMasters/\")\n",
    "import uproot \n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from lbn_modified3 import LBN, LBNLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#for some reason pylorentz is installed somewhere differently ?\n",
    "#sys.path.append(\"/eos/home-a/acraplet/.local/lib/python2.7/site-packages\")\n",
    "sys.path.append(\"/home/acraplet/Alie/Masters/ICHiggsTauTauMasters/\")\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Vector4\n",
    "from pylorentz import Position4\n",
    "\n",
    "# loading the tree\n",
    "tree = uproot.open(\"/home/acraplet/Alie/Masters/MVAFILE_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "#tree = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GluGluHToTauTauUncorrelatedDecay_Filtered_tt_2018.root\")[\"ntuple\"]\n",
    "print(\"\\n Tree loaded\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 1\n",
      "Check 1\n",
      "400190.0 This is the length\n",
      "panda Data frame created \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pi_E_1</th>\n",
       "      <th>pi_px_1</th>\n",
       "      <th>pi_py_1</th>\n",
       "      <th>pi_pz_1</th>\n",
       "      <th>pi_E_2</th>\n",
       "      <th>pi_px_2</th>\n",
       "      <th>pi_py_2</th>\n",
       "      <th>pi_pz_2</th>\n",
       "      <th>pi0_E_1</th>\n",
       "      <th>pi0_px_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ipcov10_2</th>\n",
       "      <th>ipcov11_2</th>\n",
       "      <th>ipcov12_2</th>\n",
       "      <th>ipcov20_2</th>\n",
       "      <th>ipcov21_2</th>\n",
       "      <th>ipcov22_2</th>\n",
       "      <th>metcov00</th>\n",
       "      <th>metcov01</th>\n",
       "      <th>metcov10</th>\n",
       "      <th>metcov11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.763911</td>\n",
       "      <td>4.132116</td>\n",
       "      <td>-2.350583</td>\n",
       "      <td>-0.275229</td>\n",
       "      <td>25.502320</td>\n",
       "      <td>-20.096222</td>\n",
       "      <td>13.177361</td>\n",
       "      <td>8.535096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034092e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.967108e-08</td>\n",
       "      <td>-8.706676e-07</td>\n",
       "      <td>3.967108e-08</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>174.066971</td>\n",
       "      <td>-95.040672</td>\n",
       "      <td>-95.040672</td>\n",
       "      <td>79.905930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23.598206</td>\n",
       "      <td>8.073680</td>\n",
       "      <td>17.302803</td>\n",
       "      <td>13.866671</td>\n",
       "      <td>35.317532</td>\n",
       "      <td>5.329739</td>\n",
       "      <td>27.949494</td>\n",
       "      <td>-20.921956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.890363e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.899238e-07</td>\n",
       "      <td>-2.863723e-07</td>\n",
       "      <td>3.899238e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2429.299561</td>\n",
       "      <td>678.568848</td>\n",
       "      <td>678.568848</td>\n",
       "      <td>2930.895020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>53.494987</td>\n",
       "      <td>-41.784021</td>\n",
       "      <td>32.807944</td>\n",
       "      <td>-6.279217</td>\n",
       "      <td>6.952983</td>\n",
       "      <td>0.731218</td>\n",
       "      <td>4.313461</td>\n",
       "      <td>5.402210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.538588e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-5.675425e-07</td>\n",
       "      <td>5.364135e-07</td>\n",
       "      <td>-5.675425e-07</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>350.111694</td>\n",
       "      <td>-252.906754</td>\n",
       "      <td>-252.906754</td>\n",
       "      <td>327.191010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>71.269803</td>\n",
       "      <td>9.985643</td>\n",
       "      <td>-16.439225</td>\n",
       "      <td>68.625099</td>\n",
       "      <td>10.564772</td>\n",
       "      <td>-6.779604</td>\n",
       "      <td>4.604359</td>\n",
       "      <td>6.665718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757374e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-8.362060e-07</td>\n",
       "      <td>-1.138664e-07</td>\n",
       "      <td>-8.362060e-07</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>78.484230</td>\n",
       "      <td>-52.514088</td>\n",
       "      <td>-52.514088</td>\n",
       "      <td>178.804672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>27.890112</td>\n",
       "      <td>1.953204</td>\n",
       "      <td>-24.265267</td>\n",
       "      <td>13.609582</td>\n",
       "      <td>46.071747</td>\n",
       "      <td>20.033124</td>\n",
       "      <td>41.095961</td>\n",
       "      <td>5.690543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.879217e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.435281e-07</td>\n",
       "      <td>-3.501969e-07</td>\n",
       "      <td>7.435281e-07</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>39.066010</td>\n",
       "      <td>29.357805</td>\n",
       "      <td>29.357805</td>\n",
       "      <td>248.615051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pi_E_1    pi_px_1    pi_py_1    pi_pz_1     pi_E_2    pi_px_2  \\\n",
       "entry                                                                     \n",
       "28      4.763911   4.132116  -2.350583  -0.275229  25.502320 -20.096222   \n",
       "73     23.598206   8.073680  17.302803  13.866671  35.317532   5.329739   \n",
       "102    53.494987 -41.784021  32.807944  -6.279217   6.952983   0.731218   \n",
       "126    71.269803   9.985643 -16.439225  68.625099  10.564772  -6.779604   \n",
       "145    27.890112   1.953204 -24.265267  13.609582  46.071747  20.033124   \n",
       "\n",
       "         pi_py_2    pi_pz_2  pi0_E_1  pi0_px_1  ...     ipcov10_2  ipcov11_2  \\\n",
       "entry                                           ...                            \n",
       "28     13.177361   8.535096      0.0       0.0  ...  1.034092e-06   0.000004   \n",
       "73     27.949494 -20.921956      0.0       0.0  ... -2.890363e-07   0.000002   \n",
       "102     4.313461   5.402210      0.0       0.0  ... -1.538588e-06   0.000002   \n",
       "126     4.604359   6.665718      0.0       0.0  ...  2.757374e-06   0.000006   \n",
       "145    41.095961   5.690543      0.0       0.0  ... -5.879217e-07   0.000003   \n",
       "\n",
       "          ipcov12_2     ipcov20_2     ipcov21_2  ipcov22_2     metcov00  \\\n",
       "entry                                                                     \n",
       "28     3.967108e-08 -8.706676e-07  3.967108e-08   0.000043   174.066971   \n",
       "73     3.899238e-07 -2.863723e-07  3.899238e-07   0.000009  2429.299561   \n",
       "102   -5.675425e-07  5.364135e-07 -5.675425e-07   0.000056   350.111694   \n",
       "126   -8.362060e-07 -1.138664e-07 -8.362060e-07   0.000035    78.484230   \n",
       "145    7.435281e-07 -3.501969e-07  7.435281e-07   0.000042    39.066010   \n",
       "\n",
       "         metcov01    metcov10     metcov11  \n",
       "entry                                       \n",
       "28     -95.040672  -95.040672    79.905930  \n",
       "73     678.568848  678.568848  2930.895020  \n",
       "102   -252.906754 -252.906754   327.191010  \n",
       "126    -52.514088  -52.514088   178.804672  \n",
       "145     29.357805   29.357805   248.615051  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define what variables are to be read into the dataframe\n",
    "momenta_features = [ \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", #leading charged pi 4-momentum\n",
    "              \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", #subleading charged pi 4-momentum\n",
    "              \"pi0_E_1\",\"pi0_px_1\",\"pi0_py_1\",\"pi0_pz_1\", #leading neutral pi 4-momentum\n",
    "              \"pi0_E_2\",\"pi0_px_2\",\"pi0_py_2\",\"pi0_pz_2\", #subleading neutral pi 4-momentum\n",
    "              \"gen_nu_p_1\", \"gen_nu_phi_1\", \"gen_nu_eta_1\", #leading neutrino, gen level\n",
    "              \"gen_nu_p_2\", \"gen_nu_phi_2\", \"gen_nu_eta_2\", #subleading neutrino, gen level  \n",
    "              \"pi2_E_1\", \"pi2_px_1\", \"pi2_py_1\", \"pi2_pz_1\",\n",
    "              \"pi3_E_1\", \"pi3_px_1\", \"pi3_py_1\", \"pi3_pz_1\"\n",
    "                ] \n",
    "\n",
    "other_features = [ \"ip_x_1\", \"ip_y_1\", \"ip_z_1\",        #leading impact parameter\n",
    "                   \"ip_x_2\", \"ip_y_2\", \"ip_z_2\",        #subleading impact parameter\n",
    "                   #\"y_1_1\", \"y_1_2\",\n",
    "                   \"gen_phitt\", \"ip_sig_2\", \"ip_sig_1\"\n",
    "                 ]    # ratios of energies\n",
    "\n",
    "target = [ \"met\", \"metx\", \"mety\", #\"aco_angle_1\", \"aco_angle_6\", \"aco_angle_5\", \"aco_angle_7\"\n",
    "         ]  #acoplanarity angle\n",
    "    \n",
    "selectors = [ \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "             \"mva_dm_1\",\"mva_dm_2\",\"rand\",\"wt_cp_ps\",\"wt_cp_sm\",\n",
    "            ]\n",
    "\n",
    "additional_info = [ \"sv_x_1\", \"sv_y_1\", \"sv_z_1\",\n",
    "                    \"sv_x_2\", \"sv_y_2\", \"sv_z_2\",\n",
    "                    ]\n",
    "\n",
    "sv_covariance_matrices = [\"svcov00_1\", \"svcov01_1\", \"svcov02_1\",\n",
    "                       \"svcov10_1\", \"svcov11_1\", \"svcov12_1\", \n",
    "                       \"svcov20_1\", \"svcov21_1\", \"svcov22_1\", \n",
    "                       \"svcov00_2\", \"svcov01_2\", \"svcov02_2\",\n",
    "                       \"svcov10_2\", \"svcov11_2\", \"svcov12_2\", \n",
    "                       \"svcov20_2\", \"svcov21_2\", \"svcov22_2\", \n",
    "    \n",
    "]\n",
    "\n",
    "ip_covariance_matrices = [\"ipcov00_1\", \"ipcov01_1\", \"ipcov02_1\",\n",
    "                       \"ipcov10_1\", \"ipcov11_1\", \"ipcov12_1\", \n",
    "                       \"ipcov20_1\", \"ipcov21_1\", \"ipcov22_1\", \n",
    "                       \"ipcov00_2\", \"ipcov01_2\", \"ipcov02_2\",\n",
    "                       \"ipcov10_2\", \"ipcov11_2\", \"ipcov12_2\", \n",
    "                       \"ipcov20_2\", \"ipcov21_2\", \"ipcov22_2\", \n",
    "    \n",
    "]\n",
    "\n",
    "met_covariance_matrices = [\"metcov00\", \n",
    "                           \"metcov01\", \n",
    "                           \"metcov10\", \n",
    "                           \"metcov11\" ]\n",
    "\n",
    "covs = sv_covariance_matrices + ip_covariance_matrices + met_covariance_matrices\n",
    "\n",
    "\n",
    "variables4=(momenta_features+other_features+target+selectors+additional_info + covs) #copying Kinglsey's way cause it is very clean\n",
    "print('Check 1')\n",
    "\n",
    "df4 = tree.pandas.df(variables4)\n",
    "# plt.figure()\n",
    "# plt.hist2d(df4[\"mva_dm_1\"],df4[\"mva_dm_2\"], label = 'mva_dm_2 against mva_dm_1')\n",
    "# plt.grid()\n",
    "# #plt.legend()\n",
    "# plt.savefig('The_mva_dm2d.png')\n",
    "\n",
    "print('Check 1')\n",
    "\n",
    "df4 = df4[\n",
    "      (df4[\"tau_decay_mode_1\"] == 10) \n",
    "    & (df4[\"tau_decay_mode_2\"] == 1) \n",
    "    & (df4[\"mva_dm_1\"] == 10) \n",
    "    & (df4[\"mva_dm_2\"] == 1)\n",
    "    & (df4[\"gen_nu_p_1\"] > -4000)\n",
    "    & (df4[\"gen_nu_p_2\"] > -4000)\n",
    "]\n",
    "\n",
    "print(0.7*len(df4),'This is the length') #up to here we are fine\n",
    "\n",
    "df_ps = df4[\n",
    "      (df4[\"rand\"]<df4[\"wt_cp_ps\"]/2)     #a data frame only including the pseudoscalars\n",
    "]\n",
    "\n",
    "df_sm = df4[\n",
    "      (df4[\"rand\"]<df4[\"wt_cp_sm\"]/2)     #data frame only including the scalars\n",
    "]\n",
    "\n",
    "print(\"panda Data frame created \\n\")\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will be mega slow so we do not want to do it each time !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_product(vector3_1,vector3_2):\n",
    "    if len(vector3_1)!=3 or len(vector3_1)!=3:\n",
    "        print('These are not 3D arrays !')\n",
    "    x_perp_vector=vector3_1[1]*vector3_2[2]-vector3_1[2]*vector3_2[1]\n",
    "    y_perp_vector=vector3_1[2]*vector3_2[0]-vector3_1[0]*vector3_2[2]\n",
    "    z_perp_vector=vector3_1[0]*vector3_2[1]-vector3_1[1]*vector3_2[0]\n",
    "    return np.array([x_perp_vector,y_perp_vector,z_perp_vector])\n",
    "\n",
    "def dot_product(vector1,vector2):\n",
    "    if len(vector1)!=len(vector2):\n",
    "        raise Arrays_of_different_size\n",
    "    prod=0\n",
    "    for i in range(len(vector1)):\n",
    "        prod=prod+vector1[i]*vector2[i]\n",
    "    return prod\n",
    "\n",
    "\n",
    "def norm(vector):\n",
    "    if len(vector)!=3:\n",
    "        print('This is only for a 3d vector')\n",
    "    return np.sqrt(vector[0]**2+vector[1]**2+vector[2]**2)\n",
    "\n",
    "def remove9999 (Momenta4, leading):\n",
    "    if leading == 1:\n",
    "        nu_ref = Momentum4.m_eta_phi_p(np.zeros(len(df4[\"gen_nu_phi_1\"])), df4[\"gen_nu_eta_1\"], df4[\"gen_nu_phi_1\"], df4[\"gen_nu_p_1\"])\n",
    "    if leading == 2:\n",
    "        nu_ref = Momentum4.m_eta_phi_p(np.zeros(len(df4[\"gen_nu_phi_2\"])), df4[\"gen_nu_eta_2\"], df4[\"gen_nu_phi_2\"], df4[\"gen_nu_p_2\"])\n",
    "    \n",
    "    array = np.array(Momenta4).T\n",
    "    array = array[nu_ref.p_z != 9999]\n",
    "    array = array.T\n",
    "    return Momentum4(array[0], array[1], array[2], array[3])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the usefull 4 momenta\n",
    "\n",
    "#neutrinos refs, in E, px, py, pz form\n",
    "nu_1 = Momentum4.m_eta_phi_p(np.zeros(len(df4[\"gen_nu_phi_1\"])), df4[\"gen_nu_eta_1\"], df4[\"gen_nu_phi_1\"], df4[\"gen_nu_p_1\"])\n",
    "nu_2 = Momentum4.m_eta_phi_p(np.zeros(len(df4[\"gen_nu_phi_2\"])), df4[\"gen_nu_eta_2\"], df4[\"gen_nu_phi_2\"], df4[\"gen_nu_p_2\"])\n",
    "\n",
    "#Charged and neutral pion momenta\n",
    "pi_1_4Mom = Momentum4(df4[\"pi_E_1\"],df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"])\n",
    "pi_2_4Mom = Momentum4(df4[\"pi_E_2\"],df4[\"pi_px_2\"],df4[\"pi_py_2\"],df4[\"pi_pz_2\"]) \n",
    "pi2_1_4Mom = Momentum4(df4[\"pi2_E_1\"],df4[\"pi2_px_1\"],df4[\"pi2_py_1\"],df4[\"pi2_pz_1\"])\n",
    "pi3_1_4Mom = Momentum4(df4[\"pi3_E_1\"],df4[\"pi3_px_1\"],df4[\"pi3_py_1\"],df4[\"pi3_pz_1\"])\n",
    "\n",
    "#Same for the pi0\n",
    "pi0_1_4Mom = Momentum4(df4[\"pi0_E_1\"],df4[\"pi0_px_1\"],df4[\"pi0_py_1\"],df4[\"pi0_pz_1\"])\n",
    "pi0_2_4Mom = Momentum4(df4[\"pi0_E_2\"],df4[\"pi0_px_2\"],df4[\"pi0_py_2\"],df4[\"pi0_pz_2\"])\n",
    "\n",
    "tau_1_vis = pi_1_4Mom + pi3_1_4Mom + pi2_1_4Mom # + pi0_1_4Mom #\n",
    "tau_2_vis = pi_2_4Mom + pi0_2_4Mom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-afe8b1efd3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.xlim(0,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eta_vis_1(a1) - eta_nu1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eta_vis_1(a1) - eta_nu1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vertical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         label=None, stacked=False, *, data=None, **kwargs):\n\u001b[0;32m-> 2685\u001b[0;31m     return gca().hist(\n\u001b[0m\u001b[1;32m   2686\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0mcumulative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcumulative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6716\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6717\u001b[0m                     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6718\u001b[0;31m                 bars = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[0m\u001b[1;32m   6719\u001b[0m                                 \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6720\u001b[0m                                 color=c, **{bottom_kwarg: bottom})\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m                 \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m             \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_patch\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m   2028\u001b[0m         \u001b[0mAdd\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPatch\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;31m'\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \"\"\"\n\u001b[0;32m-> 2030\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_set_artist_props\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouseover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mouseover_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mmouseover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNavigationToolbar2\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \"\"\"\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mouseover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mmouseover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist1 = tau_1_vis.eta - nu_1.eta\n",
    "hist2 = tau_2_vis.eta - nu_2.eta\n",
    "\n",
    "hist1 = tf.where(tf.math.is_inf(hist1), 999, hist1)\n",
    "\n",
    "plt.figure()\n",
    "#plt.xlim(0,5)\n",
    "plt.hist(hist1, alpha = 0.5, bins = 100, label='eta_vis_1(a1) - eta_nu1')\n",
    "plt.hist(hist2, alpha = 0.5, bins = 100, label='eta_vis_1(a1) - eta_nu1')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Colinearity approximation - eta')\n",
    "plt.xlabel('Difference between eta visible and eta neutrinos (rad)')\n",
    "plt.savefig('Eta_colinearity')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acraplet/miniconda3/envs/ICMasters/lib/python3.8/site-packages/numpy/lib/histograms.py:851: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  indices = f_indices.astype(np.intp)\n",
      "/home/acraplet/miniconda3/envs/ICMasters/lib/python3.8/site-packages/numpy/core/_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/acraplet/miniconda3/envs/ICMasters/lib/python3.8/site-packages/matplotlib/transforms.py:1966: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x, y = float(x), float(y)\n"
     ]
    }
   ],
   "source": [
    "tau_2 = tau_2_vis + nu_2\n",
    "tau_1 = tau_1_vis + nu_1\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tau_1.m, alpha = 0.5, bins=100)\n",
    "plt.hist(tau_2.m, alpha = 0.5,  bins=100)\n",
    "plt.xlabel('Mass_GEV')\n",
    "plt.xlim(0,4)\n",
    "#plt.savefig('Is_this_a1.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Here, start straining to regress neutrinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the nans of the ip values:\n",
    "# \"ip_x_1\", \"ip_y_1\", \"ip_z_1\",        #leading impact parameter\n",
    "#                    \"ip_x_2\", \"ip_y_2\", \"ip_z_2\"\n",
    "def one_d(val):\n",
    "    return tf.constant(val, shape = df4[\"pi_px_1\"].shape, dtype = np.float32)\n",
    "\n",
    "def Mom4_to_tf(Mom4_1D):\n",
    "    return tf.convert_to_tensor(Mom4_1D, dtype = 'float32')\n",
    "\n",
    "ip_x_1 = tf.where(tf.math.is_nan(df4[\"ip_x_1\"]), 0, df4[\"ip_x_1\"])\n",
    "ip_y_1 = tf.where(tf.math.is_nan(df4[\"ip_y_1\"]), 0, df4[\"ip_y_1\"])\n",
    "ip_z_1 = tf.where(tf.math.is_nan(df4[\"ip_z_1\"]), 0, df4[\"ip_z_1\"])\n",
    "ip_x_2 = tf.where(tf.math.is_nan(df4[\"ip_x_2\"]), 0, df4[\"ip_x_2\"])\n",
    "ip_y_2 = tf.where(tf.math.is_nan(df4[\"ip_y_2\"]), 0, df4[\"ip_y_2\"])\n",
    "ip_z_2 = tf.where(tf.math.is_nan(df4[\"ip_z_2\"]), 0, df4[\"ip_z_2\"])\n",
    "\n",
    "\n",
    "sv_x_1 = tf.where(tf.math.is_nan(df4[\"sv_x_1\"]), 0, df4[\"sv_x_1\"])\n",
    "sv_y_1 = tf.where(tf.math.is_nan(df4[\"sv_y_1\"]), 0, df4[\"sv_y_1\"])\n",
    "sv_z_1 = tf.where(tf.math.is_nan(df4[\"sv_z_1\"]), 0, df4[\"sv_z_1\"])\n",
    "sv_x_2 = tf.where(tf.math.is_nan(df4[\"sv_x_2\"]), 0, df4[\"sv_x_2\"])\n",
    "sv_y_2 = tf.where(tf.math.is_nan(df4[\"sv_y_2\"]), 0, df4[\"sv_y_2\"])\n",
    "sv_z_2 = tf.where(tf.math.is_nan(df4[\"sv_z_2\"]), 0, df4[\"sv_z_2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571700,)\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lab_frame (InputLayer)       [(None, 571700, 22)]      0         \n",
      "_________________________________________________________________\n",
      "learning (Dense)             (None, 571700, 300)       6900      \n",
      "_________________________________________________________________\n",
      "learning2 (Dense)            (None, 571700, 300)       90300     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 571700, 300)       0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 571700, 14)        4214      \n",
      "=================================================================\n",
      "Total params: 101,414\n",
      "Trainable params: 101,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 571700, 22) for input Tensor(\"lab_frame:0\", shape=(None, 571700, 22), dtype=float32), but it was called on an input with incompatible shape (None, 22).\n",
      "WARNING:tensorflow:AutoGraph could not transform <function loss_D_p at 0x7f38bc73f1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp4esh0gtj.py, line 21)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function loss_D_p at 0x7f38bc73f1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp4esh0gtj.py, line 21)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(None,) this is shape\n",
      "(None,) this is shape\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 571700, 22) for input Tensor(\"lab_frame:0\", shape=(None, 571700, 22), dtype=float32), but it was called on an input with incompatible shape (None, 22).\n",
      "(None,) this is shape\n",
      "(None,) this is shape\n",
      "799/801 [============================>.] - ETA: 0s - loss: 21.1864 - mae: 36.0561 - loss_D_p: 0.1983 - loss_phi: 9.0767 - loss_p: 10.3161 - loss_mass_tau: 0.6617 - loss_mass_Higgs: 0.9336WARNING:tensorflow:Model was constructed with shape (None, 571700, 22) for input Tensor(\"lab_frame:0\", shape=(None, 571700, 22), dtype=float32), but it was called on an input with incompatible shape (None, 22).\n",
      "(None,) this is shape\n",
      "(None,) this is shape\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 21.1787 - mae: 36.0543 - loss_D_p: 0.1983 - loss_phi: 9.0717 - loss_p: 10.3141 - loss_mass_tau: 0.6613 - loss_mass_Higgs: 0.9333 - val_loss: 21.7690 - val_mae: 40.1509 - val_loss_D_p: 0.2512 - val_loss_phi: 6.3833 - val_loss_p: 13.7709 - val_loss_mass_tau: 0.4846 - val_loss_mass_Higgs: 0.8790\n",
      "Epoch 2/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 17.1155 - mae: 35.5388 - loss_D_p: 0.1655 - loss_phi: 6.8137 - loss_p: 8.9304 - loss_mass_tau: 0.3983 - loss_mass_Higgs: 0.8076 - val_loss: 20.2644 - val_mae: 39.6186 - val_loss_D_p: 0.2320 - val_loss_phi: 6.2416 - val_loss_p: 12.4552 - val_loss_mass_tau: 0.4571 - val_loss_mass_Higgs: 0.8784\n",
      "Epoch 3/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 18.2723 - mae: 35.6756 - loss_D_p: 0.1657 - loss_phi: 8.1969 - loss_p: 8.5885 - loss_mass_tau: 0.4921 - loss_mass_Higgs: 0.8291 - val_loss: 20.6323 - val_mae: 39.7862 - val_loss_D_p: 0.2383 - val_loss_phi: 6.5393 - val_loss_p: 12.3524 - val_loss_mass_tau: 0.6223 - val_loss_mass_Higgs: 0.8800\n",
      "Epoch 4/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.9888 - mae: 35.4537 - loss_D_p: 0.1598 - loss_phi: 7.2520 - loss_p: 8.3451 - loss_mass_tau: 0.4297 - loss_mass_Higgs: 0.8022 - val_loss: 24.9708 - val_mae: 39.5629 - val_loss_D_p: 0.2275 - val_loss_phi: 11.3940 - val_loss_p: 11.9556 - val_loss_mass_tau: 0.5189 - val_loss_mass_Higgs: 0.8748\n",
      "Epoch 5/25\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 16.4708 - mae: 35.2953 - loss_D_p: 0.1570 - loss_phi: 6.8947 - loss_p: 8.1879 - loss_mass_tau: 0.4289 - loss_mass_Higgs: 0.8023 - val_loss: 18.9994 - val_mae: 39.2863 - val_loss_D_p: 0.2135 - val_loss_phi: 5.9176 - val_loss_p: 11.6415 - val_loss_mass_tau: 0.3939 - val_loss_mass_Higgs: 0.8328\n",
      "Epoch 6/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.0764 - mae: 35.1107 - loss_D_p: 0.1532 - loss_phi: 6.6741 - loss_p: 8.0643 - loss_mass_tau: 0.3962 - loss_mass_Higgs: 0.7887 - val_loss: 18.1020 - val_mae: 39.1586 - val_loss_D_p: 0.2125 - val_loss_phi: 5.2553 - val_loss_p: 11.4073 - val_loss_mass_tau: 0.3952 - val_loss_mass_Higgs: 0.8318\n",
      "Epoch 7/25\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 16.4368 - mae: 35.1028 - loss_D_p: 0.1547 - loss_phi: 7.0478 - loss_p: 8.0102 - loss_mass_tau: 0.4269 - loss_mass_Higgs: 0.7972 - val_loss: 18.2221 - val_mae: 39.3170 - val_loss_D_p: 0.2169 - val_loss_phi: 5.0750 - val_loss_p: 11.6350 - val_loss_mass_tau: 0.4473 - val_loss_mass_Higgs: 0.8480\n",
      "Epoch 8/25\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 15.7495 - mae: 34.9817 - loss_D_p: 0.1506 - loss_phi: 6.5134 - loss_p: 7.9273 - loss_mass_tau: 0.3800 - loss_mass_Higgs: 0.7782 - val_loss: 24.3681 - val_mae: 39.4957 - val_loss_D_p: 0.2411 - val_loss_phi: 10.7394 - val_loss_p: 11.6933 - val_loss_mass_tau: 0.7476 - val_loss_mass_Higgs: 0.9467\n",
      "Epoch 9/25\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 17.1942 - mae: 35.3284 - loss_D_p: 0.1586 - loss_phi: 7.7310 - loss_p: 8.0069 - loss_mass_tau: 0.4819 - loss_mass_Higgs: 0.8158 - val_loss: 17.9376 - val_mae: 39.5040 - val_loss_D_p: 0.2151 - val_loss_phi: 4.9047 - val_loss_p: 11.5393 - val_loss_mass_tau: 0.4332 - val_loss_mass_Higgs: 0.8453\n",
      "Epoch 10/25\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 15.8303 - mae: 35.1949 - loss_D_p: 0.1499 - loss_phi: 6.6380 - loss_p: 7.8714 - loss_mass_tau: 0.3903 - loss_mass_Higgs: 0.7807 - val_loss: 20.2317 - val_mae: 39.4837 - val_loss_D_p: 0.2102 - val_loss_phi: 7.4769 - val_loss_p: 11.3358 - val_loss_mass_tau: 0.3914 - val_loss_mass_Higgs: 0.8174\n",
      "Epoch 11/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.8290 - mae: 35.3050 - loss_D_p: 0.1543 - loss_phi: 7.5394 - loss_p: 7.8876 - loss_mass_tau: 0.4569 - loss_mass_Higgs: 0.7907 - val_loss: 18.4401 - val_mae: 39.7303 - val_loss_D_p: 0.2192 - val_loss_phi: 5.4798 - val_loss_p: 11.4312 - val_loss_mass_tau: 0.4726 - val_loss_mass_Higgs: 0.8374\n",
      "Epoch 12/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.1120 - mae: 35.4705 - loss_D_p: 0.1544 - loss_phi: 6.8844 - loss_p: 7.8457 - loss_mass_tau: 0.4353 - loss_mass_Higgs: 0.7923 - val_loss: 17.0561 - val_mae: 39.8977 - val_loss_D_p: 0.2129 - val_loss_phi: 4.4725 - val_loss_p: 11.0394 - val_loss_mass_tau: 0.4822 - val_loss_mass_Higgs: 0.8491\n",
      "Epoch 13/25\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 16.2203 - mae: 35.5821 - loss_D_p: 0.1533 - loss_phi: 6.9942 - loss_p: 7.8359 - loss_mass_tau: 0.4482 - loss_mass_Higgs: 0.7888 - val_loss: 18.0662 - val_mae: 40.0356 - val_loss_D_p: 0.2109 - val_loss_phi: 5.2117 - val_loss_p: 11.3967 - val_loss_mass_tau: 0.4142 - val_loss_mass_Higgs: 0.8328\n",
      "Epoch 14/25\n",
      "801/801 [==============================] - 6s 8ms/step - loss: 16.5662 - mae: 35.5629 - loss_D_p: 0.1531 - loss_phi: 7.3430 - loss_p: 7.8186 - loss_mass_tau: 0.4573 - loss_mass_Higgs: 0.7942 - val_loss: 18.0796 - val_mae: 39.9095 - val_loss_D_p: 0.2098 - val_loss_phi: 5.2767 - val_loss_p: 11.3412 - val_loss_mass_tau: 0.4229 - val_loss_mass_Higgs: 0.8290\n",
      "Epoch 15/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.0219 - mae: 35.6651 - loss_D_p: 0.1505 - loss_phi: 6.9096 - loss_p: 7.7571 - loss_mass_tau: 0.4293 - loss_mass_Higgs: 0.7754 - val_loss: 18.5352 - val_mae: 39.9335 - val_loss_D_p: 0.2174 - val_loss_phi: 5.8231 - val_loss_p: 11.1316 - val_loss_mass_tau: 0.5164 - val_loss_mass_Higgs: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 15.3359 - mae: 35.6650 - loss_D_p: 0.1478 - loss_phi: 6.3706 - loss_p: 7.6435 - loss_mass_tau: 0.4065 - loss_mass_Higgs: 0.7676 - val_loss: 16.3155 - val_mae: 39.8327 - val_loss_D_p: 0.2003 - val_loss_phi: 4.1623 - val_loss_p: 10.8082 - val_loss_mass_tau: 0.3511 - val_loss_mass_Higgs: 0.7936\n",
      "Epoch 17/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 15.6138 - mae: 35.8444 - loss_D_p: 0.1477 - loss_phi: 6.6441 - loss_p: 7.6336 - loss_mass_tau: 0.4209 - loss_mass_Higgs: 0.7676 - val_loss: 17.5212 - val_mae: 40.2167 - val_loss_D_p: 0.2043 - val_loss_phi: 5.0392 - val_loss_p: 11.0451 - val_loss_mass_tau: 0.4117 - val_loss_mass_Higgs: 0.8209\n",
      "Epoch 18/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.2077 - mae: 35.9228 - loss_D_p: 0.1492 - loss_phi: 7.1816 - loss_p: 7.6568 - loss_mass_tau: 0.4450 - loss_mass_Higgs: 0.7751 - val_loss: 17.1468 - val_mae: 40.0016 - val_loss_D_p: 0.2041 - val_loss_phi: 4.8591 - val_loss_p: 10.8374 - val_loss_mass_tau: 0.4469 - val_loss_mass_Higgs: 0.7994\n",
      "Epoch 19/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 16.4713 - mae: 35.8086 - loss_D_p: 0.1506 - loss_phi: 7.4236 - loss_p: 7.6427 - loss_mass_tau: 0.4714 - loss_mass_Higgs: 0.7831 - val_loss: 18.0094 - val_mae: 39.9834 - val_loss_D_p: 0.2153 - val_loss_phi: 5.2542 - val_loss_p: 11.1508 - val_loss_mass_tau: 0.5332 - val_loss_mass_Higgs: 0.8559\n",
      "Epoch 20/25\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 16.8791 - mae: 35.7782 - loss_D_p: 0.1512 - loss_phi: 7.8265 - loss_p: 7.6402 - loss_mass_tau: 0.4759 - loss_mass_Higgs: 0.7853 - val_loss: 24.3946 - val_mae: 39.9157 - val_loss_D_p: 0.2316 - val_loss_phi: 11.0624 - val_loss_p: 11.5274 - val_loss_mass_tau: 0.6785 - val_loss_mass_Higgs: 0.8946\n",
      "Epoch 21/25\n",
      "801/801 [==============================] - 6s 8ms/step - loss: 16.1765 - mae: 35.6236 - loss_D_p: 0.1511 - loss_phi: 7.1069 - loss_p: 7.6757 - loss_mass_tau: 0.4607 - loss_mass_Higgs: 0.7822 - val_loss: 20.5196 - val_mae: 39.8887 - val_loss_D_p: 0.2150 - val_loss_phi: 7.9204 - val_loss_p: 10.9775 - val_loss_mass_tau: 0.5724 - val_loss_mass_Higgs: 0.8341\n",
      "Epoch 22/25\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 16.1882 - mae: 35.5151 - loss_D_p: 0.1498 - loss_phi: 7.2176 - loss_p: 7.5732 - loss_mass_tau: 0.4690 - loss_mass_Higgs: 0.7786 - val_loss: 18.4219 - val_mae: 39.6942 - val_loss_D_p: 0.2157 - val_loss_phi: 6.1432 - val_loss_p: 10.7108 - val_loss_mass_tau: 0.5221 - val_loss_mass_Higgs: 0.8302\n",
      "Epoch 23/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 15.6849 - mae: 35.4978 - loss_D_p: 0.1487 - loss_phi: 6.7626 - loss_p: 7.5476 - loss_mass_tau: 0.4547 - loss_mass_Higgs: 0.7712 - val_loss: 16.4715 - val_mae: 39.5584 - val_loss_D_p: 0.2019 - val_loss_phi: 4.2107 - val_loss_p: 10.8911 - val_loss_mass_tau: 0.3729 - val_loss_mass_Higgs: 0.7948\n",
      "Epoch 24/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 14.3186 - mae: 35.3896 - loss_D_p: 0.1414 - loss_phi: 5.6780 - loss_p: 7.3829 - loss_mass_tau: 0.3786 - loss_mass_Higgs: 0.7377 - val_loss: 17.2022 - val_mae: 39.5999 - val_loss_D_p: 0.2055 - val_loss_phi: 5.0385 - val_loss_p: 10.6940 - val_loss_mass_tau: 0.4590 - val_loss_mass_Higgs: 0.8052\n",
      "Epoch 25/25\n",
      "801/801 [==============================] - 5s 6ms/step - loss: 15.2501 - mae: 35.4633 - loss_D_p: 0.1453 - loss_phi: 6.4971 - loss_p: 7.4115 - loss_mass_tau: 0.4422 - loss_mass_Higgs: 0.7540 - val_loss: 20.6897 - val_mae: 39.8033 - val_loss_D_p: 0.2152 - val_loss_phi: 8.2856 - val_loss_p: 10.8029 - val_loss_mass_tau: 0.5677 - val_loss_mass_Higgs: 0.8183\n"
     ]
    }
   ],
   "source": [
    "# Start training here: would work better with small dataset !\n",
    "# Here copying the result from the KIT paper\n",
    "\n",
    "smear_px, smear_py = one_d(0), one_d(0)   #the smearing of the detector, we don't know yet what it is\n",
    "\n",
    "ref = [#smear_px,py                      #0\n",
    "       #one_d(1.776),                      #1\n",
    "       #df4[\"metx\"],                   #2\n",
    "       #df4[\"mety\"],                   #3\n",
    "       Mom4_to_tf(tau_1_vis.e),       #4\n",
    "       Mom4_to_tf(tau_1_vis.p_x),     #5\n",
    "       Mom4_to_tf(tau_1_vis.p_y),     #6\n",
    "       Mom4_to_tf(tau_1_vis.p_z),     #7\n",
    "       Mom4_to_tf(tau_2_vis.e),       #8\n",
    "       Mom4_to_tf(tau_2_vis.p_x),     #9 \n",
    "       Mom4_to_tf(tau_2_vis.p_y),     #10\n",
    "       Mom4_to_tf(tau_2_vis.p_z),     #11\n",
    "       #one_d(125),                    #12\n",
    "       #Mom4_to_tf(nu_1.e),            #13       corresponding to          #0\n",
    "       Mom4_to_tf(nu_1.p_x),          #14                                 #1\n",
    "       Mom4_to_tf(nu_1.p_y),          #15                                 #2\n",
    "       Mom4_to_tf(nu_1.p_z),          #16                                 #3\n",
    "       #Mom4_to_tf(nu_2.e),            #17                                 #4\n",
    "       Mom4_to_tf(nu_2.p_x),          #18                                 #5\n",
    "       Mom4_to_tf(nu_2.p_y),          #19                                 #6\n",
    "       Mom4_to_tf(nu_2.p_z),          #20                                 #7\n",
    "]\n",
    "\n",
    "\n",
    "#i_smear_px = 0\n",
    "#i_tau_mass = 0\n",
    "#i_smeared_met_px = 1\n",
    "#i_smeared_met_py = 2\n",
    "i_tau1_e = 0\n",
    "i_tau1_px = 1\n",
    "i_tau1_py = 2\n",
    "i_tau1_pz = 3\n",
    "i_tau2_e = 4\n",
    "i_tau2_px = 5\n",
    "i_tau2_py = 6\n",
    "i_tau2_pz = 7\n",
    "#i_gen_mass = 9\n",
    "#i_nu1_e = 12\n",
    "i_nu1_px = 8\n",
    "i_nu1_py = 9\n",
    "i_nu1_pz = 10\n",
    "#i_nu2_e = 16\n",
    "i_nu2_px = 11\n",
    "i_nu2_py = 12\n",
    "i_nu2_pz = 13\n",
    "\n",
    "####Very important, the batch size must be defined beforehand to get rid of two trainable params !\n",
    "B_size = 500#2**10\n",
    "\n",
    "m_Higgs_squared = 125**2\n",
    "\n",
    "\n",
    "m_tau_squared = 1.776**2\n",
    "\n",
    "def one_d_traning(val, shape_array):\n",
    "    return tf.constant(val, shape = shape_array.shape, dtype = np.float32)\n",
    "\n",
    "ref = tf.transpose(ref)\n",
    "\n",
    "def loss_D_p (y_true, y_pred):\n",
    "    global ratio_all\n",
    "    #calculting the difference between the the components, need to add the smearing of detector eventually\n",
    "    target_components = [i_nu1_px, i_nu1_py, i_nu1_pz, i_nu2_px, i_nu2_py, i_nu2_pz]\n",
    "    target_components_diff_list = []\n",
    "    for i in target_components: target_components_diff_list.append((y_true[:,i]-y_pred[:,i])**2)\n",
    "    dxyz = 0\n",
    "    for d in target_components_diff_list: dxyz+=d\n",
    "    return ratio_all * dxyz #tone it down cause it takes too much space\n",
    "\n",
    "def energy_nu (y_true, y_pred, number):\n",
    "    if number == 1:\n",
    "        return tf.sqrt(y_pred[:, i_nu1_px]**2 + y_pred[:, i_nu1_py]**2 + y_pred[:, i_nu1_pz]**2)\n",
    "    if number == 2:\n",
    "        return tf.sqrt(y_pred[:, i_nu2_px]**2 + y_pred[:, i_nu2_py]**2 + y_pred[:, i_nu2_pz]**2)\n",
    "\n",
    "def loss_mass_tau(y_true, y_pred):\n",
    "    #now we try only to use the y_pred for neutrino info, this is I guess their way of \n",
    "    #only training for neutrino info whilst keeping nice structure\n",
    "    #we are always assuming m=0\n",
    "    # note, we are taking y_tau as exact, we could choose not to...\n",
    "    global ratio_tau\n",
    "    E1 = y_true[:, i_tau1_e] + energy_nu(y_true, y_pred, 1) \n",
    "    P1_squared = (y_true[:, i_tau1_px] + y_pred[:, i_nu1_px])**2 + (y_true[:, i_tau1_py] + y_pred[:, i_nu1_py])**2 + (y_true[:, i_tau1_pz] + y_pred[:, i_nu1_pz])**2\n",
    "    R1 = (E1**2 - P1_squared -  m_tau_squared)/m_Higgs_squared\n",
    "    \n",
    "    E2 = y_true[:, i_tau2_e] + energy_nu(y_true, y_pred, 2) \n",
    "    P2_squared = (y_true[:, i_tau2_px] + y_pred[:, i_nu2_px])**2 + (y_true[:, i_tau2_py] + y_pred[:, i_nu2_py])**2 + (y_true[:, i_tau2_pz] + y_pred[:, i_nu2_pz])**2\n",
    "    R2 = (E2**2 - P2_squared - m_tau_squared)/m_Higgs_squared\n",
    "    return ratio_tau * (tf.math.abs(R1) + tf.abs(R2))\n",
    "\n",
    "\n",
    "def loss_mass_Higgs(y_true, y_pred):\n",
    "    global ratio_H\n",
    "    print(tf.convert_to_tensor(y_pred[:, 0]).shape, 'this is shape')\n",
    "    EH = y_true[:, i_tau1_e] + energy_nu(y_true, y_pred, 1) + y_true[:, i_tau2_e] + energy_nu(y_true, y_pred, 2)\n",
    "    px_H = y_true[:, i_tau1_px] + y_true[:, i_tau2_px] + y_pred[:, i_nu1_px] + y_pred[:, i_nu2_px]\n",
    "    py_H = y_true[:, i_tau1_py] + y_true[:, i_tau2_py] + y_pred[:, i_nu1_py] + y_pred[:, i_nu2_py]\n",
    "    pz_H = y_true[:, i_tau1_pz] + y_true[:, i_tau2_pz] + y_pred[:, i_nu1_pz] + y_pred[:, i_nu2_pz]\n",
    "#      y_true[:, i_gen_mass]**2\n",
    "    return ratio_H* tf.abs((EH**2-px_H**2-py_H**2-pz_H**2 -m_Higgs_squared)/m_Higgs_squared)\n",
    "\n",
    "\n",
    "def loss_phi(y_true, y_pred):\n",
    "    global ratio_phi\n",
    "    phi_diff_1 = (tf.math.atan2(y_pred[:, i_nu1_py],y_pred[:, i_nu1_px])-tf.math.atan2(y_true[:, i_nu1_py],y_true[:, i_nu1_px]))**2\n",
    "    phi_diff_2 = (tf.math.atan2(y_pred[:, i_nu2_py],y_pred[:, i_nu2_px])-tf.math.atan2(y_true[:, i_nu2_py],y_true[:, i_nu2_px]))**2\n",
    "\n",
    "    \n",
    "    return ratio_phi*tf.convert_to_tensor(phi_diff_1+phi_diff_2) #tone it up\n",
    "\n",
    "\n",
    "def loss_p(y_true, y_pred):\n",
    "    global ratio_p\n",
    "    delta_p1 = (energy_nu(y_true,y_pred, 1) - tf.sqrt(y_true[:, i_nu1_px]**2 + y_true[:, i_nu1_py]**2 + y_true[:, i_nu1_pz]**2))**2\n",
    "    delta_p2 = (energy_nu(y_true,y_pred, 2) - tf.sqrt(y_true[:, i_nu2_px]**2 + y_true[:, i_nu2_py]**2 + y_true[:, i_nu2_pz]**2))**2\n",
    "    \n",
    "    return ratio_p*tf.convert_to_tensor(delta_p1+delta_p2) #tone it up\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "\n",
    "    dxyz = loss_D_p(y_true, y_pred)\n",
    "    #dmet = loss_dmet(y_true, y_pred)\n",
    "    #dPTtaus = loss_dPTtaus(y_true, y_pred)\n",
    "    dphi = loss_phi(y_true,y_pred)\n",
    "    dtau = loss_mass_tau(y_true, y_pred)\n",
    "    dHiggs = loss_mass_Higgs(y_true, y_pred)\n",
    "    dp = loss_p(y_true, y_pred)\n",
    "    #dM = loss_dM_had(y_true, y_pred)\n",
    "\n",
    "    return dxyz + dtau + dHiggs + dphi + dp\n",
    "\n",
    "\n",
    "nu_1_training = np.array(nu_1)[0]\n",
    "\n",
    "print(nu_1_training.shape)\n",
    "\n",
    "n = -1\n",
    "\n",
    "x = np.array([\n",
    "              #smear_px,\n",
    "              #smear_py,\n",
    "              df4[\"metx\"],\n",
    "              df4[\"mety\"], \n",
    "              Mom4_to_tf(tau_1_vis.e),\n",
    "              Mom4_to_tf(tau_1_vis.p_x),\n",
    "              Mom4_to_tf(tau_1_vis.p_y),\n",
    "              Mom4_to_tf(tau_1_vis.p_z),\n",
    "              Mom4_to_tf(tau_2_vis.e),\n",
    "              Mom4_to_tf(tau_2_vis.p_x),\n",
    "              Mom4_to_tf(tau_2_vis.p_y),\n",
    "              Mom4_to_tf(tau_2_vis.p_z),\n",
    "              ip_x_1, \n",
    "              ip_y_1, \n",
    "              ip_z_1, \n",
    "              ip_x_2, \n",
    "              ip_y_2, \n",
    "              ip_z_2,\n",
    "              df4[\"ip_sig_2\"],\n",
    "              df4[\"ip_sig_1\"],\n",
    "              #Mom4_to_tf(nu_1.p_x),\n",
    "              #df4[\"ip_x_1\"], \n",
    "              #df4[\"ip_y_1\"], \n",
    "              #df4[\"ip_z_1\"],        #leading impact parameter\n",
    "              #df4[\"ip_x_2\"], \n",
    "              #df4[\"ip_y_2\"], \n",
    "              #df4[\"ip_z_2\"],\n",
    "              df4[\"met\"],  \n",
    "              sv_x_1, \n",
    "              sv_y_1, \n",
    "              sv_z_1,\n",
    "              #sv_x_2, \n",
    "              #sv_y_2, \n",
    "              #sv_z_2\n",
    "             ])\n",
    "x = tf.transpose(x)\n",
    "\n",
    "y = ref\n",
    "\n",
    "ratio_tau = 10\n",
    "ratio_H = 4\n",
    "ratio_all = 1/10000\n",
    "ratio_p = 10/1500\n",
    "ratio_phi = 4\n",
    "\n",
    "\n",
    "trainFrac = 0.7\n",
    "numTrain = int(trainFrac*x.shape[0])\n",
    "x_train = x[:numTrain]\n",
    "y_train = y[:numTrain]\n",
    "\n",
    "x_val = x[numTrain:]\n",
    "y_val = y[numTrain:]\n",
    "\n",
    "input_1 = tf.keras.Input(shape = x.shape, name=\"lab_frame\")\n",
    "x2 = tf.keras.layers.Dense(300, activation = 'relu', name=\"learning\")(input_1)\n",
    "#,kernel_regularizer=tf.keras.regularizers.L1L2(2)\n",
    "#kernel_regularizer=tf.keras.regularizers.L2(0.2),\n",
    "#x4 = tf.keras.layers.Dropout(0.5, name=\"dropout\")(x2)\n",
    "# x6 = tf.keras.layers.Dense(11, activation = 'relu', name=\"learning1\")(x2)\n",
    "\n",
    "#x5 = tf.keras.layers.Dropout(0.4, name=\"dropout\")(x201\n",
    "# x3 = tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.01), name=\"learning2\")(x2)\n",
    "\n",
    "x3 = tf.keras.layers.Dense(300, activation = 'relu', name=\"learning2\")(x2)\n",
    "\n",
    "\n",
    "# kernel_regularizer=tf.keras.regularizers.L1L2(2)\n",
    "# kernel_regularizer=tf.keras.regularizers.L2(0.2),\n",
    "x4 = tf.keras.layers.Dropout(0.1, name=\"dropout2\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(300, activation = 'elu', name=\"learning3\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning3\")(x3)\n",
    "output = tf.keras.layers.Dense(14, name=\"output\")(x4)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_1],\n",
    "    outputs=[output],\n",
    ")\n",
    "\n",
    "y = ref\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(loss = loss_fn, optimizer = 'adam', metrics = ['mae', loss_D_p, loss_phi, loss_p, loss_mass_tau, loss_mass_Higgs])#, loss_mass_Higgs, loss_mass_tau, loss_D_p])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size = B_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All means\n",
      "All means\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Here verify the eta component\n",
    "\n",
    "\n",
    "def checks(x_array, length):\n",
    "    \n",
    "    regressed_array = model({\"lab_frame\": x_array})\n",
    "\n",
    "    #length = 0#numTrain\n",
    "\n",
    "    E_1 = norm([regressed_array[:, i_nu1_py],regressed_array[:, i_nu1_py], regressed_array[:, i_nu1_pz]])\n",
    "    E_2 = norm([regressed_array[:, i_nu2_py],regressed_array[:, i_nu2_py], regressed_array[:, i_nu2_pz]])\n",
    "\n",
    "\n",
    "    nu_1_regressed = Momentum4(E_1,regressed_array[:, i_nu1_px],regressed_array[:, i_nu1_py], regressed_array[:, i_nu1_pz])\n",
    "    nu_2_regressed = Momentum4(E_2,regressed_array[:, i_nu2_px],regressed_array[:, i_nu2_py], regressed_array[:, i_nu2_pz])\n",
    "\n",
    "\n",
    "    print('All means')\n",
    "\n",
    "    hist1 = nu_1_regressed.p_x\n",
    "    hist2 = Mom4_to_tf(nu_1.p_x)[length:]\n",
    "    hist_a = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.p_x\n",
    "    hist2 = Mom4_to_tf(nu_2.p_x)[length:]\n",
    "    hist_b = np.array(hist2-hist1) #\n",
    "    hist1 = nu_1_regressed.p_y\n",
    "    hist2 = Mom4_to_tf(nu_1.p_y)[length:]\n",
    "    hist_c = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.p_y\n",
    "    hist2 = Mom4_to_tf(nu_2.p_y)[length:]\n",
    "    hist_l = np.array(hist2-hist1) #\n",
    "    hist1 = nu_1_regressed.p_z\n",
    "    hist2 = Mom4_to_tf(nu_1.p_z)[length:]\n",
    "    hist_d = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.p_z\n",
    "    hist2 = Mom4_to_tf(nu_2.p_z)[length:]\n",
    "    hist_e = np.array(hist2-hist1) #\n",
    "    hist1 = nu_1_regressed.phi\n",
    "    hist2 = Mom4_to_tf(nu_1.phi)[length:]\n",
    "    hist_f = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.phi\n",
    "    hist2 = Mom4_to_tf(nu_2.phi)[length:]\n",
    "    hist_g = np.array(hist2-hist1) #\n",
    "    hist1 = nu_1_regressed.eta\n",
    "    hist2 = Mom4_to_tf(nu_1.eta)[length:]\n",
    "    hist_h = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.eta\n",
    "    hist2 = Mom4_to_tf(nu_2.eta)[length:]\n",
    "    hist_i = np.array(hist2-hist1) #\n",
    "    hist1 = nu_1_regressed.p\n",
    "    hist2 = Mom4_to_tf(nu_1.p)[length:]\n",
    "    hist_j = np.array(hist2-hist1) #\n",
    "    hist1 = nu_2_regressed.p\n",
    "    hist2 = Mom4_to_tf(nu_2.p)[length:]\n",
    "    hist_k = np.array(hist2-hist1) #\n",
    "\n",
    "    return [hist_a.mean(), hist_b.mean(), hist_c.mean(), hist_d.mean(), hist_l.mean(), hist_e.mean(), \n",
    "            hist_f.mean(), hist_g.mean(), hist_h.mean(), hist_i.mean(), hist_j.mean(), hist_k.mean()], [hist_a.std(), hist_b.std(), hist_c.std(), hist_d.std(), hist_l.std(), hist_e.std(), \n",
    "            hist_f.std(), hist_g.std(), hist_h.mean(), hist_i.std(), hist_j.std(), hist_k.std()]\n",
    "\n",
    "    \n",
    "\n",
    "mean_x_val, std_x_val = checks(x_val, numTrain)\n",
    "mean_x, std_x = checks(x, 0)\n",
    "\n",
    "\n",
    "    \n",
    "table = [mean_x_val, std_x_val, mean_x, std_x]\n",
    "\n",
    "table = np.array(table).T\n",
    "\n",
    "np.savetxt('check.txt', table, fmt = '%.2f')\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('means')\n",
    "\n",
    "# print('%.2f'%hist_a.mean())\n",
    "# print('%.2f'%hist_b.mean())\n",
    "# print('%.2f'%hist_c.mean())\n",
    "# print('%.2f'%hist_d.mean())\n",
    "# print('%.2f'%hist_b.mean())\n",
    "# print('%.2f'%hist_e.mean())\n",
    "# print('%.2f'%hist_f.mean())\n",
    "# print('%.2f'%hist_g.mean())\n",
    "# print('%.2f'%hist_h.mean())\n",
    "# print('%.2f'%hist_i.mean())\n",
    "# print('%.2f'%hist_j.mean())\n",
    "# print('%.2f'%hist_k.mean())\n",
    "\n",
    "\n",
    "# print ('stds')\n",
    "\n",
    "# print('%.2f'%hist_a.std())\n",
    "# print('%.2f'%hist_b.std())\n",
    "# print('%.2f'%hist_c.std())\n",
    "# print('%.2f'%hist_d.std())\n",
    "# print('%.2f'%hist_b.std())\n",
    "# print('%.2f'%hist_e.std())\n",
    "# print('%.2f'%hist_f.std())\n",
    "# print('%.2f'%hist_g.std())\n",
    "# print('%.2f'%hist_h.std())\n",
    "# print('%.2f'%hist_i.std())\n",
    "# print('%.2f'%hist_j.std())\n",
    "# print('%.2f'%hist_k.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then Try simple NN to regress only the phi component of the two neutrinos simultaneously\n",
    "\n",
    "x = [Mom4_to_tf(tau_1_vis.e),\n",
    "     Mom4_to_tf(tau_1_vis.p_x),\n",
    "     Mom4_to_tf(tau_1_vis.p_y),\n",
    "     Mom4_to_tf(tau_1_vis.p_z),\n",
    "     Mom4_to_tf(tau_1_vis.phi),\n",
    "     Mom4_to_tf(tau_2_vis.e),\n",
    "     Mom4_to_tf(tau_2_vis.p_x),\n",
    "     Mom4_to_tf(tau_2_vis.p_y),\n",
    "     Mom4_to_tf(tau_2_vis.p_z),\n",
    "     Mom4_to_tf(tau_2_vis.phi),\n",
    "     df4['met'],\n",
    "     df4['metx'],\n",
    "     df4['mety']\n",
    "    ]\n",
    "x = tf.transpose(x)\n",
    "\n",
    "y = [Mom4_to_tf(nu_1.phi), Mom4_to_tf(nu_2.phi)]\n",
    "\n",
    "y = tf.transpose(y)\n",
    "\n",
    "\n",
    "# def loss_fn_phi(y_true, y_pred):\n",
    "#     return (tf.math.cos(y_true)-tf.math.cos(y_pred))**2\n",
    "\n",
    "input_1 = tf.keras.Input(shape = x.shape, name=\"lab_frame\")\n",
    "\n",
    "x2 = tf.keras.layers.Dense(64, activation = 'relu', name=\"learning\")(input_1)\n",
    "x3 = tf.keras.layers.Dense(64, activation = 'relu', name=\"learning2\")(x2)\n",
    "x4 = tf.keras.layers.Dropout(0.1, name=\"dropout\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(300, activation = 'relu', name=\"learning3\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning3\")(x3)\n",
    "#x5 = tf.keras.layers.Dense(500, activation = 'elu', name=\"learning4\")(x4)\n",
    "#x6 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning5\")(x5)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, name=\"output\")(x4)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_1],\n",
    "    outputs=[output],\n",
    ")\n",
    "\n",
    "# t = tau_1_vis_loss\n",
    "# y_ = y.T\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss_fn_phi = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss = loss_fn_phi, optimizer = 'adam', metrics = ['mae'])#, loss_mass_Higgs, loss_mass_tau, loss_D_p])\n",
    "\n",
    "history = model.fit(x, y, validation_split = 0.3,\n",
    "    epochs=50,\n",
    "    batch_size = 500)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the 'quality check' section\n",
    "fig = plt.figure(figsize=(10,10), frameon = True)\n",
    "\n",
    "plt.title('Quality check: 300-300-300-o,\\ninputs exclude mets, output exclude met. Batch: 500')\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -6])\n",
    "hist2 = np.array(y_val[:, -6])\n",
    "hist_a = hist2-hist1\n",
    "plt.hist(hist_a, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_1\\nMean: %.2f, std: %.2f\"%(hist_a.mean(), hist_a.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -5])\n",
    "hist2 = np.array(y_val[:, -5])\n",
    "hist_b = hist2-hist1\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_1\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -4])\n",
    "hist2 = np.array(y_val[:, -4])\n",
    "hist_c = hist2-hist1\n",
    "plt.hist(hist_c, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_1\\nMean: %.2f, std: %.2f\"%(hist_c.mean(), hist_c.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(-50,50)\n",
    "plt.ylabel('Occurences')\n",
    "         \n",
    "         \n",
    "ax = fig.add_subplot(2,1,2)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -3])\n",
    "hist2 = np.array(y_val[:, -3])\n",
    "hist_d = hist2-hist1\n",
    "plt.hist(hist_d, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_2\\nMean: %.2f, std: %.2f\"%(hist_d.mean(), hist_d.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -2])\n",
    "hist2 = np.array(y_val[:, -2])\n",
    "hist_e = hist2-hist1\n",
    "plt.hist(hist_e, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_2\\nMean: %.2f, std: %.2f\"%(hist_e.mean(), hist_e.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x_val})[:, -1])\n",
    "hist2 = np.array(y_val[:, -1])\n",
    "hist_f = hist2-hist1\n",
    "plt.hist(hist_f, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_2\\nMean: %.2f, std: %.2f\"%(hist_f.mean(), hist_f.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Difference of Momenta component')\n",
    "plt.ylabel('Occurences')\n",
    "plt.xlim(-50,50)\n",
    "\n",
    "plt.savefig('4_vect_qual_500_500_B500_R_val.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here verify the phi component\n",
    "\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "hist1 = tf.math.atan2(model({\"lab_frame\": x_val})[:, i_nu1_py], model({\"lab_frame\": x_val})[:, i_nu1_px])\n",
    "hist2 = Mom4_to_tf(nu_1.phi)[numTrain:]\n",
    "hist_b = np.array(hist2-hist1)\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_phi_1\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "hist1 = tf.math.atan2(model({\"lab_frame\": x_val})[:, i_nu2_py], model({\"lab_frame\": x_val})[:, i_nu2_px])\n",
    "hist2 = Mom4_to_tf(nu_2.phi)[numTrain:]\n",
    "hist_b = np.array(hist2-hist1)\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_phi_2\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(-2,2)\n",
    "plt.xlabel('Difference of phi component')\n",
    "\n",
    "plt.savefig('Phi_qual_500_500_B500_R_val.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here verify the eta component\n",
    "\n",
    "regressed_array = model({\"lab_frame\": x})\n",
    "\n",
    "E_1 = norm([regressed_array[:, i_nu1_py],regressed_array[:, i_nu1_py], regressed_array[:, i_nu1_pz]])\n",
    "E_2 = norm([regressed_array[:, i_nu2_py],regressed_array[:, i_nu2_py], regressed_array[:, i_nu2_pz]])\n",
    "\n",
    "\n",
    "nu_1_regressed = Momentum4(E_1,regressed_array[:, i_nu1_px],regressed_array[:, i_nu1_py], regressed_array[:, i_nu1_pz])\n",
    "nu_2_regressed = Momentum4(E_2,regressed_array[:, i_nu2_px],regressed_array[:, i_nu2_py], regressed_array[:, i_nu2_pz])\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "hist1 = nu_1_regressed.p_x\n",
    "hist2 = Mom4_to_tf(nu_1.p_x)#[numTrain:]\n",
    "hist_b = np.array(hist2-hist1) #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_eta_1\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "hist1 = nu_2_regressed.p_y\n",
    "hist2 = Mom4_to_tf(nu_2.p_y)#[numTrain:]\n",
    "hist_b = np.array(hist2-hist1)\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_eta_2\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.xlim(-2,2)\n",
    "plt.xlabel('Difference of phi component')\n",
    "\n",
    "plt.savefig('Phi_qual_500_500_B500_phi_all.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 2\n",
    "\n",
    "         \n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 968192, 10) for input Tensor(\"lab_frame_4:0\", shape=(None, 968192, 10), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 968192, 10) for input Tensor(\"lab_frame_4:0\", shape=(None, 968192, 10), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
      "1356/1356 [==============================] - ETA: 0s - loss: 1917.6036 - mae: 39.9942WARNING:tensorflow:Model was constructed with shape (None, 968192, 10) for input Tensor(\"lab_frame_4:0\", shape=(None, 968192, 10), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
      "1356/1356 [==============================] - 15s 11ms/step - loss: 1917.6036 - mae: 39.9942 - val_loss: 2610.1282 - val_mae: 43.4733\n",
      "Epoch 2/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1699.7272 - mae: 39.6700 - val_loss: 2597.8945 - val_mae: 43.7552\n",
      "Epoch 3/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1677.6960 - mae: 39.7335 - val_loss: 2549.5977 - val_mae: 43.7872\n",
      "Epoch 4/50\n",
      "1356/1356 [==============================] - 14s 11ms/step - loss: 1663.7881 - mae: 39.7429 - val_loss: 2485.2976 - val_mae: 43.4555\n",
      "Epoch 5/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1651.1306 - mae: 39.8377 - val_loss: 2494.3550 - val_mae: 43.6106\n",
      "Epoch 6/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1643.9099 - mae: 39.8467 - val_loss: 2494.1179 - val_mae: 43.6432\n",
      "Epoch 7/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1634.3356 - mae: 39.8797 - val_loss: 2473.9553 - val_mae: 43.6530\n",
      "Epoch 8/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1630.4716 - mae: 39.8815 - val_loss: 2447.2979 - val_mae: 43.7359\n",
      "Epoch 9/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1622.0109 - mae: 39.8931 - val_loss: 2495.3511 - val_mae: 43.7103\n",
      "Epoch 10/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1621.7166 - mae: 39.9172 - val_loss: 2460.1260 - val_mae: 43.6831\n",
      "Epoch 11/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1612.5052 - mae: 39.9166 - val_loss: 2489.4316 - val_mae: 43.7947\n",
      "Epoch 12/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1608.5955 - mae: 39.9081 - val_loss: 2459.4163 - val_mae: 43.7122\n",
      "Epoch 13/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1608.4413 - mae: 39.9142 - val_loss: 2539.3528 - val_mae: 43.5760\n",
      "Epoch 14/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1605.4712 - mae: 39.9686 - val_loss: 2489.7297 - val_mae: 43.7217\n",
      "Epoch 15/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1597.7333 - mae: 39.9655 - val_loss: 2440.1936 - val_mae: 43.7354\n",
      "Epoch 16/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1597.1824 - mae: 39.9943 - val_loss: 2457.0183 - val_mae: 43.6589\n",
      "Epoch 17/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1594.3080 - mae: 40.0058 - val_loss: 2459.9612 - val_mae: 43.7222\n",
      "Epoch 18/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1594.0132 - mae: 40.0000 - val_loss: 2500.2651 - val_mae: 43.9251\n",
      "Epoch 19/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1583.8054 - mae: 40.0577 - val_loss: 2491.0281 - val_mae: 43.9807\n",
      "Epoch 20/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1583.2651 - mae: 40.0868 - val_loss: 2514.5571 - val_mae: 43.5606\n",
      "Epoch 21/50\n",
      "1356/1356 [==============================] - 17s 12ms/step - loss: 1577.4895 - mae: 40.0679 - val_loss: 2529.6833 - val_mae: 44.0536\n",
      "Epoch 22/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1576.4879 - mae: 40.1033 - val_loss: 2492.8384 - val_mae: 43.8942\n",
      "Epoch 23/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1571.1874 - mae: 40.1227 - val_loss: 2472.2207 - val_mae: 44.0561\n",
      "Epoch 24/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1571.9403 - mae: 40.1778 - val_loss: 2503.5684 - val_mae: 43.8279\n",
      "Epoch 25/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1569.0905 - mae: 40.1779 - val_loss: 2468.4170 - val_mae: 43.9947\n",
      "Epoch 26/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1565.1615 - mae: 40.2022 - val_loss: 2486.9824 - val_mae: 43.9508\n",
      "Epoch 27/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1558.7700 - mae: 40.2188 - val_loss: 2475.9065 - val_mae: 43.9619\n",
      "Epoch 28/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1558.1907 - mae: 40.2382 - val_loss: 2498.5112 - val_mae: 44.0257\n",
      "Epoch 29/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1552.7136 - mae: 40.2349 - val_loss: 2520.7000 - val_mae: 44.1866\n",
      "Epoch 30/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1550.0940 - mae: 40.2576 - val_loss: 2521.6653 - val_mae: 44.0729\n",
      "Epoch 31/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1544.7440 - mae: 40.2847 - val_loss: 2521.4771 - val_mae: 44.0893\n",
      "Epoch 32/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1541.3024 - mae: 40.3077 - val_loss: 2508.6287 - val_mae: 44.3325\n",
      "Epoch 33/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1540.9872 - mae: 40.3195 - val_loss: 2512.3147 - val_mae: 44.1629\n",
      "Epoch 34/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1533.9865 - mae: 40.3493 - val_loss: 2603.9446 - val_mae: 44.5622\n",
      "Epoch 35/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1531.9338 - mae: 40.3968 - val_loss: 2521.9021 - val_mae: 44.1406\n",
      "Epoch 36/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1533.7352 - mae: 40.3765 - val_loss: 2516.8896 - val_mae: 44.1622\n",
      "Epoch 37/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1524.0305 - mae: 40.4048 - val_loss: 2547.2910 - val_mae: 44.3408\n",
      "Epoch 38/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1518.9465 - mae: 40.4270 - val_loss: 2515.4958 - val_mae: 44.2166\n",
      "Epoch 39/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1518.4982 - mae: 40.4616 - val_loss: 2521.7163 - val_mae: 44.2120\n",
      "Epoch 40/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1514.5626 - mae: 40.4721 - val_loss: 2532.1399 - val_mae: 44.0862\n",
      "Epoch 41/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1511.2383 - mae: 40.4589 - val_loss: 2528.5022 - val_mae: 44.4758\n",
      "Epoch 42/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1508.4866 - mae: 40.5074 - val_loss: 2568.1223 - val_mae: 44.6798\n",
      "Epoch 43/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1507.3695 - mae: 40.5364 - val_loss: 2515.4834 - val_mae: 44.3125\n",
      "Epoch 44/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1500.6742 - mae: 40.5202 - val_loss: 2521.2170 - val_mae: 44.2737\n",
      "Epoch 45/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1492.9366 - mae: 40.5404 - val_loss: 2560.5671 - val_mae: 44.5046\n",
      "Epoch 46/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1492.0536 - mae: 40.5596 - val_loss: 2558.2803 - val_mae: 44.4379\n",
      "Epoch 47/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1490.9824 - mae: 40.6010 - val_loss: 2512.8352 - val_mae: 44.4544\n",
      "Epoch 48/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1488.2098 - mae: 40.6221 - val_loss: 2557.1802 - val_mae: 44.5234\n",
      "Epoch 49/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1477.4401 - mae: 40.6374 - val_loss: 2577.4529 - val_mae: 44.5623\n",
      "Epoch 50/50\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1483.1232 - mae: 40.6474 - val_loss: 2570.5508 - val_mae: 44.5914\n"
     ]
    }
   ],
   "source": [
    "x = np.array([one_d(125), \n",
    "              one_d(1.776),\n",
    "              #smear_px,\n",
    "              #smear_py,\n",
    "              #df4[\"metx\"],\n",
    "              #df4[\"mety\"], \n",
    "              Mom4_to_tf(tau_1_vis.e),\n",
    "              Mom4_to_tf(tau_1_vis.p_x),\n",
    "              Mom4_to_tf(tau_1_vis.p_y),\n",
    "              Mom4_to_tf(tau_1_vis.p_z),\n",
    "              Mom4_to_tf(tau_2_vis.e),\n",
    "              Mom4_to_tf(tau_2_vis.p_x),\n",
    "              Mom4_to_tf(tau_2_vis.p_y),\n",
    "              Mom4_to_tf(tau_2_vis.p_z),\n",
    "              #df4[\"met\"]\n",
    "             ])\n",
    "x = tf.transpose(x)\n",
    "\n",
    "y = ref\n",
    "\n",
    "input_1 = tf.keras.Input(shape = x.shape, name=\"lab_frame\")\n",
    "\n",
    "x2 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning\")(input_1)\n",
    "x3 = tf.keras.layers.Dense(300, activation = 'elu', name=\"learning2\")(x2)\n",
    "x4 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning3\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning3\")(x3)\n",
    "#x5 = tf.keras.layers.Dense(500, activation = 'elu', name=\"learning4\")(x4)\n",
    "#x6 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning5\")(x5)\n",
    "\n",
    "output = tf.keras.layers.Dense(16, name=\"output\")(x4)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_1],\n",
    "    outputs=[output],\n",
    ")\n",
    "\n",
    "#tf.keras.losses.MeanSquaredError() #common to the 4 iterations\n",
    "model.compile(loss = loss_fn, optimizer = 'adam', metrics = ['mae'])#, loss_mass_Higgs, loss_mass_tau, loss_D_p])\n",
    "\n",
    "history = model.fit(x, y, validation_split = 0.3,\n",
    "    epochs=50,\n",
    "    batch_size = 500)\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "#This is the 'quality check' section\n",
    "fig = plt.figure('2_fig', figsize=(10,10), frameon = True)\n",
    "\n",
    "plt.title('Quality check: 500-300-500-o,\\ninputs exclude mets, output exclude met. Batch: 500')\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -6])\n",
    "hist2 = np.array(y[:, -6])\n",
    "hist_a = hist2-hist1\n",
    "plt.hist(hist_a, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_1\\nMean: %.2f, std: %.2f\"%(hist_a.mean(), hist_a.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -5])\n",
    "hist2 = np.array(y[:, -5])\n",
    "hist_b = hist2-hist1\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_1\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -4])\n",
    "hist2 = np.array(y[:, -4])\n",
    "hist_c = hist2-hist1\n",
    "plt.hist(hist_c, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_1\\nMean: %.2f, std: %.2f\"%(hist_c.mean(), hist_c.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(-50,50)\n",
    "plt.ylabel('Occurences')\n",
    "         \n",
    "         \n",
    "ax = fig.add_subplot(2,1,2)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -3])\n",
    "hist2 = np.array(y[:, -3])\n",
    "hist_d = hist2-hist1\n",
    "plt.hist(hist_d, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_2\\nMean: %.2f, std: %.2f\"%(hist_d.mean(), hist_d.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -2])\n",
    "hist2 = np.array(y[:, -2])\n",
    "hist_e = hist2-hist1\n",
    "plt.hist(hist_e, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_2\\nMean: %.2f, std: %.2f\"%(hist_e.mean(), hist_e.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -1])\n",
    "hist2 = np.array(y[:, -1])\n",
    "hist_f = hist2-hist1\n",
    "plt.hist(hist_f, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_2\\nMean: %.2f, std: %.2f\"%(hist_f.mean(), hist_f.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Difference of Momenta component')\n",
    "plt.ylabel('Occurences')\n",
    "plt.xlim(-50,50)\n",
    "\n",
    "plt.savefig('Quality_500_300_500_1_500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Traning 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.22657775e-05 8.39220302e-05 7.18750016e-06 ... 6.93282782e-05\n",
      " 1.77967231e-05 9.17172201e-06], shape=(571700,), dtype=float32)\n",
      "tf.Tensor([0.02934769 0.20486112 0.01050362 ... 0.12745337 0.02100937 0.00848406], shape=(571700,), dtype=float32)\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 571700, 19) for input Tensor(\"lab_frame_4:0\", shape=(None, 571700, 19), dtype=float32), but it was called on an input with incompatible shape (None, 19).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 571700, 19) for input Tensor(\"lab_frame_4:0\", shape=(None, 571700, 19), dtype=float32), but it was called on an input with incompatible shape (None, 19).\n",
      "800/801 [============================>.] - ETA: 0s - loss: 1329.1543 - mae: 38.1922WARNING:tensorflow:Model was constructed with shape (None, 571700, 19) for input Tensor(\"lab_frame_4:0\", shape=(None, 571700, 19), dtype=float32), but it was called on an input with incompatible shape (None, 19).\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1329.0811 - mae: 38.1916 - val_loss: nan - val_mae: nan\n",
      "Epoch 2/50\n",
      "582/801 [====================>.........] - ETA: 2s - loss: 1029.9915 - mae: 37.2705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-6673a7632ad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, loss_mass_Higgs, loss_mass_tau, loss_D_p])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m history = model.fit(x, y, validation_split = 0.3,\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     batch_size = 500)\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here copying the result from the KIT paper\n",
    "\n",
    "smear_px, smear_py = one_d(0), one_d(0)   #the smearing of the detector, we don't know yet what it is\n",
    "\n",
    "ref = [#smear_px,py                      #0\n",
    "       one_d(1.776),                      #1\n",
    "       df4[\"metx\"],                   #2\n",
    "       df4[\"mety\"],                   #3\n",
    "       Mom4_to_tf(tau_1_vis.e),       #4\n",
    "       Mom4_to_tf(tau_1_vis.p_x),     #5\n",
    "       Mom4_to_tf(tau_1_vis.p_y),     #6\n",
    "       Mom4_to_tf(tau_1_vis.p_z),     #7\n",
    "       Mom4_to_tf(tau_2_vis.e),       #8\n",
    "       Mom4_to_tf(tau_2_vis.p_x),     #9 \n",
    "       Mom4_to_tf(tau_2_vis.p_y),     #10\n",
    "       Mom4_to_tf(tau_2_vis.p_z),     #11\n",
    "       one_d(125),                    #12\n",
    "       #Mom4_to_tf(nu_1.e),            #13       corresponding to          #0\n",
    "       Mom4_to_tf(nu_1.p_x),          #14                                 #1\n",
    "       Mom4_to_tf(nu_1.p_y),          #15                                 #2\n",
    "       Mom4_to_tf(nu_1.p_z),          #16                                 #3\n",
    "       #Mom4_to_tf(nu_2.e),            #17                                 #4\n",
    "       Mom4_to_tf(nu_2.p_x),          #18                                 #5\n",
    "       Mom4_to_tf(nu_2.p_y),          #19                                 #6\n",
    "       Mom4_to_tf(nu_2.p_z),          #20                                 #7\n",
    "]\n",
    "\n",
    "\n",
    "#i_smear_px = 0\n",
    "i_tau_mass = 0\n",
    "i_smeared_met_px = 1\n",
    "i_smeared_met_py = 2\n",
    "i_tau1_e = 3\n",
    "i_tau1_px = 4\n",
    "i_tau1_py = 5\n",
    "i_tau1_pz = 6\n",
    "i_tau2_e = 7\n",
    "i_tau2_px = 8\n",
    "i_tau2_py = 9\n",
    "i_tau2_pz = 10\n",
    "i_gen_mass = 11\n",
    "#i_nu1_e = 12\n",
    "i_nu1_px = 12\n",
    "i_nu1_py = 13\n",
    "i_nu1_pz = 14\n",
    "#i_nu2_e = 16\n",
    "i_nu2_px = 15\n",
    "i_nu2_py = 16\n",
    "i_nu2_pz = 17\n",
    "\n",
    "\n",
    "m_tau_squared = tf.transpose(one_d(1.776)**2)\n",
    "\n",
    "ref = tf.transpose(ref)\n",
    "\n",
    "def loss_D_p (y_true, y_pred):\n",
    "    #calculting the difference between the the components, need to add the smearing of detector eventually\n",
    "    target_components = [i_nu1_px, i_nu1_py, i_nu1_pz, i_nu2_px, i_nu2_py, i_nu2_pz]\n",
    "    target_components_diff_list = []\n",
    "    for i in target_components: target_components_diff_list.append((y_true[:,i]-y_pred[:,i])**2)\n",
    "    dxyz = 0\n",
    "    for d in target_components_diff_list: dxyz+=d\n",
    "    return dxyz\n",
    "\n",
    "def energy_nu (y_true, y_pred, number):\n",
    "    if number == 1:\n",
    "        return tf.sqrt(y_pred[:, i_nu1_px]**2 + y_pred[:, i_nu1_py]**2 + y_pred[:, i_nu1_pz]**2)\n",
    "    if number == 2:\n",
    "        return tf.sqrt(y_pred[:, i_nu2_px]**2 + y_pred[:, i_nu2_py]**2 + y_pred[:, i_nu2_pz]**2)\n",
    "\n",
    "def loss_mass_tau(y_true, y_pred):\n",
    "    #now we try only to use the y_pred for neutrino info, this is I guess their way of \n",
    "    #only training for neutrino info whilst keeping nice structure\n",
    "    #we are always assuming m=0\n",
    "    # note, we are taking y_tau as exact, we could choose not to...\n",
    "    E1 = y_true[:, i_tau1_e] + energy_nu(y_true, y_pred, 1) \n",
    "    P1_squared = (y_true[:, i_tau1_px] + y_pred[:, i_nu1_px])**2 + (y_true[:, i_tau1_py] + y_pred[:, i_nu1_py])**2 + (y_true[:, i_tau1_pz] + y_pred[:, i_nu1_pz])**2\n",
    "    R1 = (E1**2 - P1_squared - y_true[:, i_tau_mass]**2)/(y_true[:, i_gen_mass])**2\n",
    "    \n",
    "    E2 = y_true[:, i_tau2_e] + energy_nu(y_true, y_pred, 2) \n",
    "    P2_squared = (y_true[:, i_tau2_px] + y_pred[:, i_nu2_px])**2 + (y_true[:, i_tau2_py] + y_pred[:, i_nu2_py])**2 + (y_true[:, i_tau2_pz] + y_pred[:, i_nu2_pz])**2\n",
    "    R2 = (E2**2 - P2_squared - y_true[:, i_tau_mass]**2)/(y_true[:, i_gen_mass])**2\n",
    "    return tf.math.abs(R1) + tf.abs(R2)\n",
    "\n",
    "\n",
    "def loss_mass_Higgs(y_true, y_pred):\n",
    "    EH = y_true[:, i_tau1_e] + energy_nu(y_true, y_pred, 1) + y_true[:, i_tau2_e] + energy_nu(y_true, y_pred, 2)\n",
    "    px_H = y_true[:, i_tau1_px] + y_true[:, i_tau2_px] + y_pred[:, i_nu1_px] + y_pred[:, i_nu2_px]\n",
    "    py_H = y_true[:, i_tau1_py] + y_true[:, i_tau2_py] + y_pred[:, i_nu1_py] + y_pred[:, i_nu2_py]\n",
    "    pz_H = y_true[:, i_tau1_pz] + y_true[:, i_tau2_pz] + y_pred[:, i_nu1_pz] + y_pred[:, i_nu2_pz]\n",
    "    \n",
    "    return tf.abs((EH**2-px_H**2-py_H**2-pz_H**2 - y_true[:, i_gen_mass]**2)/(y_true[:,i_gen_mass])**2)\n",
    "    \n",
    "\n",
    "print(loss_mass_tau(ref,ref))\n",
    "print(loss_mass_Higgs(ref,ref))\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "\n",
    "    dxyz = loss_D_p(y_true, y_pred)\n",
    "    #dmet = loss_dmet(y_true, y_pred)\n",
    "    #dPTtaus = loss_dPTtaus(y_true, y_pred)\n",
    "    dtau = loss_mass_tau(y_true, y_pred)\n",
    "    dHiggs = loss_mass_Higgs(y_true, y_pred)\n",
    "    #dM = loss_dM_had(y_true, y_pred)\n",
    "\n",
    "    return dxyz + dtau + dHiggs\n",
    "\n",
    "\n",
    "x = np.array([one_d(125), \n",
    "              one_d(1.776),\n",
    "              #smear_px,\n",
    "              #smear_py,\n",
    "              df4[\"metx\"],\n",
    "              df4[\"mety\"], \n",
    "              Mom4_to_tf(tau_1_vis.e),\n",
    "              Mom4_to_tf(tau_1_vis.p_x),\n",
    "              Mom4_to_tf(tau_1_vis.p_y),\n",
    "              Mom4_to_tf(tau_1_vis.p_z),\n",
    "              Mom4_to_tf(tau_2_vis.e),\n",
    "              Mom4_to_tf(tau_2_vis.p_x),\n",
    "              Mom4_to_tf(tau_2_vis.p_y),\n",
    "              Mom4_to_tf(tau_2_vis.p_z),\n",
    "              df4[\"met\"],\n",
    "\n",
    "             ])\n",
    "x = tf.transpose(x)\n",
    "\n",
    "y = ref\n",
    "\n",
    "\n",
    "input_1 = tf.keras.Input(shape = x.shape, name=\"lab_frame\")\n",
    "\n",
    "x2 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning\")(input_1)\n",
    "x3 = tf.keras.layers.Dense(500, activation = 'elu', name=\"learning3\")(x2)\n",
    "#x4 = tf.keras.layers.Dense(100, activation = 'elu', name=\"learning3\")(x3)\n",
    "#x4 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning3\")(x3)\n",
    "#x5 = tf.keras.layers.Dense(500, activation = 'elu', name=\"learning4\")(x4)\n",
    "#x6 = tf.keras.layers.Dense(500, activation = 'relu', name=\"learning5\")(x5)\n",
    "\n",
    "output = tf.keras.layers.Dense(18, name=\"output\")(x3)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_1],\n",
    "    outputs=[output],\n",
    ")\n",
    "\n",
    "model.summary\n",
    "\n",
    "#tf.keras.losses.MeanSquaredError() #common to the 4 iterations\n",
    "model.compile(loss = loss_fn, optimizer = 'adam', metrics = ['mae'])#, loss_mass_Higgs, loss_mass_tau, loss_D_p])\n",
    "\n",
    "history = model.fit(x, y, validation_split = 0.3,\n",
    "    epochs=50,\n",
    "    batch_size = 500)\n",
    "\n",
    "\n",
    "\n",
    "#This is the 'quality check' section\n",
    "fig = plt.figure('2_fig', figsize=(10,10), frameon = True)\n",
    "\n",
    "plt.title('Quality check: 300-300-o,\\ninputs include mets, output include met. Batch: 500')\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -6])\n",
    "hist2 = np.array(y[:, -6])\n",
    "hist_a = hist2-hist1\n",
    "plt.hist(hist_a, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_1\\nMean: %.2f, std: %.2f\"%(hist_a.mean(), hist_a.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -5])\n",
    "hist2 = np.array(y[:, -5])\n",
    "hist_b = hist2-hist1\n",
    "plt.hist(hist_b, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_1\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -4])\n",
    "hist2 = np.array(y[:, -4])\n",
    "hist_c = hist2-hist1\n",
    "plt.hist(hist_c, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_1\\nMean: %.2f, std: %.2f\"%(hist_c.mean(), hist_c.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(-50,50)\n",
    "plt.ylabel('Occurences')\n",
    "         \n",
    "         \n",
    "ax = fig.add_subplot(2,1,2)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -3])\n",
    "hist2 = np.array(y[:, -3])\n",
    "hist_d = hist2-hist1\n",
    "plt.hist(hist_d, bins = 100, alpha = 0.5,label = \"True-Regressed nu_px_2\\nMean: %.2f, std: %.2f\"%(hist_d.mean(), hist_d.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -2])\n",
    "hist2 = np.array(y[:, -2])\n",
    "hist_e = hist2-hist1\n",
    "plt.hist(hist_e, bins = 100, alpha = 0.5,label = \"True-Regressed nu_py_2\\nMean: %.2f, std: %.2f\"%(hist_e.mean(), hist_e.std()))\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, -1])\n",
    "hist2 = np.array(y[:, -1])\n",
    "hist_f = hist2-hist1\n",
    "plt.hist(hist_f, bins = 100, alpha = 0.5,label = \"True-Regressed nu_pz_2\\nMean: %.2f, std: %.2f\"%(hist_f.mean(), hist_f.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Difference of Momenta component')\n",
    "plt.ylabel('Occurences')\n",
    "plt.xlim(-50,50)\n",
    "\n",
    "plt.savefig('Quality_300_300_include_met_500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0.1561270904944474 0\n"
     ]
    }
   ],
   "source": [
    "hist1 = np.array(model({\"lab_frame\": x})[:, -2])\n",
    "\n",
    "print(len(model({\"lab_frame\": x})[1]))\n",
    "hist2 = np.array(y[:, -2])\n",
    "need = \"nu_1_E\"\n",
    "dd = 0\n",
    "\n",
    "def frac(d = -2):\n",
    "    difference = y[:, 0]-model({\"lab_frame\": x})[:, 0]\n",
    "    difference = np.reshape(difference, [-1])\n",
    "    l = np.where(abs(difference)<=10**(d),1,0)\n",
    "    print(float(float(np.sum(l))/len(l)), d)\n",
    "    return float(float(np.sum(l))/len(l))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(hist1, bins = 100, alpha = 0.5,label = \"NN %s component : fraction($\\Delta$<$10^{%.1f}$)=%.3f \"%(need, dd, frac(dd)))\n",
    "plt.hist(hist2, bins = 100, alpha = 0.5,label = 'True %s - Features: phi_CP_1 (fixed)'%need)      \n",
    "plt.ylabel(\"Frequency\", fontsize = 'x-large')\n",
    "plt.xlabel(\"%s\"%(need), fontsize = 'x-large')\n",
    "plt.grid()\n",
    "#plt.xlim(0,400)\n",
    "plt.legend()#prop = {'size', 10})\n",
    "plt.savefig('neutrino_next_2_300_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculation:\n",
    "    \"\"\"\n",
    "    Class for calculating the aco_angle variables\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        #this is the function doing all the calculations manually just takes as input the dataframe\n",
    "        #The different *initial* 4 vectors, (E,px,py,pz)\n",
    "        self.pi_1 = np.array([df[\"pi_E_1\"],df[\"pi_px_1\"],df[\"pi_py_1\"],df[\"pi_pz_1\"]])\n",
    "        self.pi_2 = np.array([df[\"pi_E_2\"],df[\"pi_px_2\"],df[\"pi_py_2\"],df[\"pi_pz_2\"]])\n",
    "\n",
    "        self.pi0_1 = np.array([df[\"pi0_E_1\"],df[\"pi0_px_1\"],df[\"pi0_py_1\"],df[\"pi0_pz_1\"]])\n",
    "        self.pi0_2 = np.array([df[\"pi0_E_2\"],df[\"pi0_px_2\"],df[\"pi0_py_2\"],df[\"pi0_pz_2\"]])\n",
    "\n",
    "        #Charged and neutral pion momenta\n",
    "        self.pi_1_4Mom = Momentum4(df[\"pi_E_1\"],df[\"pi_px_1\"],df[\"pi_py_1\"],df[\"pi_pz_1\"])\n",
    "        self.pi_2_4Mom = Momentum4(df[\"pi_E_2\"],df[\"pi_px_2\"],df[\"pi_py_2\"],df[\"pi_pz_2\"])\n",
    "\n",
    "        #Same for the pi0\n",
    "        self.pi0_1_4Mom = Momentum4(df[\"pi0_E_1\"],df[\"pi0_px_1\"],df[\"pi0_py_1\"],df[\"pi0_pz_1\"])\n",
    "        self.pi0_2_4Mom = Momentum4(df[\"pi0_E_2\"],df[\"pi0_px_2\"],df[\"pi0_py_2\"],df[\"pi0_pz_2\"])\n",
    "\n",
    "        self.impact_param_1 = Momentum4(np.zeros(len(df[\"ip_x_1\"])),df[\"ip_x_1\"],df[\"ip_y_1\"],df[\"ip_z_1\"])\n",
    "        self.impact_param_2 = Momentum4(np.zeros(len(df[\"ip_x_2\"])),df[\"ip_x_2\"],df[\"ip_y_2\"],df[\"ip_z_2\"])\n",
    "\n",
    "        #comment or uncomment depending on which aco_angle you want \n",
    "        #self.pi0_1_4Mom = self.impact_param_1\n",
    "        #self.pi0_2_4Mom = self.impact_param_2\n",
    "\n",
    "        #This is the COM frame of the two charged pions w.r.t. which we'll boost\n",
    "        self.ref_COM_4Mom = Momentum4(self.pi_1_4Mom+self.pi_2_4Mom)\n",
    "        boost = Momentum4(self.ref_COM_4Mom[0], -self.ref_COM_4Mom[1], -self.ref_COM_4Mom[2], -self.ref_COM_4Mom[3])\n",
    "        \n",
    "        \n",
    "        boost = -self.ref_COM_4Mom\n",
    "        #energies=[df4[\"pi_E_1\"],df4[\"pi_E_2\"],df4[\"pi0_E_1\"],df4[\"pi0_E_2\"]]\n",
    "\n",
    "        #Lorentz boost everything in the ZMF of the two charged pions\n",
    "        self.pi0_1_4Mom_star = self.pi0_1_4Mom.boost_particle(boost)\n",
    "        self.pi0_2_4Mom_star = self.pi0_2_4Mom.boost_particle(boost)\n",
    "\n",
    "        #Lorentz boost everything in the ZMF of the two neutral pions\n",
    "        self.pi_1_4Mom_star = self.pi_1_4Mom.boost_particle(boost)\n",
    "        self.pi_2_4Mom_star = self.pi_2_4Mom.boost_particle(boost)\n",
    "\n",
    "\n",
    "        #calculating the perpependicular component\n",
    "        pi0_1_3Mom_star_perp=cross_product(self.pi0_1_4Mom_star[1:], self.pi_1_4Mom_star[1:])\n",
    "        pi0_2_3Mom_star_perp=cross_product(self.pi0_2_4Mom_star[1:], self.pi_2_4Mom_star[1:])\n",
    "\n",
    "        #Now normalise:\n",
    "        pi0_1_3Mom_star_perp=pi0_1_3Mom_star_perp/norm(pi0_1_3Mom_star_perp)\n",
    "        pi0_2_3Mom_star_perp=pi0_2_3Mom_star_perp/norm(pi0_2_3Mom_star_perp)\n",
    "\n",
    "        self.pi0_1_4Mom_star_perp = [self.pi0_1_4Mom_star[0], pi0_1_3Mom_star_perp[0], \n",
    "                                     pi0_1_3Mom_star_perp[1], pi0_1_3Mom_star_perp[2]]\n",
    "\n",
    "        self.pi0_2_4Mom_star_perp = [self.pi0_1_4Mom_star[0], pi0_2_3Mom_star_perp[0], \n",
    "                                     pi0_2_3Mom_star_perp[1], pi0_2_3Mom_star_perp[2]]\n",
    "\n",
    "        #Calculating phi_star\n",
    "        self.phi_CP_unshifted = np.arccos(dot_product(pi0_1_3Mom_star_perp,pi0_2_3Mom_star_perp))\n",
    "        \n",
    "        print(self.phi_CP_unshifted[:10],'This is phi_CP')\n",
    "\n",
    "        self.phi_CP = self.phi_CP_unshifted\n",
    "        \n",
    "        print(pi0_1_3Mom_star_perp[:,23], 'this is pi0_1_3mom')\n",
    "\n",
    "        #The energy ratios\n",
    "        self.y_T = np.array(df['y_1_1']*df['y_1_2'])\n",
    "\n",
    "        #The O variable\n",
    "        cross = np.array(np.cross(pi0_1_3Mom_star_perp.transpose(),pi0_2_3Mom_star_perp.transpose()).transpose())\n",
    "        self.bigO = dot_product(self.pi_2_4Mom_star[1:],cross)\n",
    "        \n",
    "        print(self.bigO[:10], '\\n this is big0')\n",
    "\n",
    "        #perform the shift w.r.t. O* sign\n",
    "        \n",
    "        \n",
    "        #phi_CP=np.where(self.bigO>=0, 2*np.pi-self.phi_CP_unshifted, self.phi_CP_unshifted)\n",
    "        self.phi_CP_1 = np.where(self.bigO>=0, 2*np.pi-self.phi_CP_unshifted, self.phi_CP_unshifted)\n",
    "        \n",
    "        print(self.phi_CP_1[:10], '\\n this is after first shft')\n",
    "\n",
    "       # self.phi_CP_2 = np.where(self.y_T<=0, self.phi_CP+np.pi, self.phi_CP-np.pi)\n",
    "\n",
    "        #additionnal shift that needs to be done do see differences between odd and even scenarios, with y=Energy ratios\n",
    "        self.phi_CP = np.where(self.y_T>=0, np.where(self.phi_CP_1<np.pi, self.phi_CP_1+np.pi, self.phi_CP_1-np.pi), self.phi_CP_1)\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        print(self.phi_CP[:10], 'this is full')\n",
    "        \n",
    "        self.y = df[\"aco_angle_1\"]\n",
    "    \n",
    "    def checks(self):\n",
    "\n",
    "        target = [self.df[\"aco_angle_1\"]]#self.df[\"aco_angle_7\"]]\n",
    "        y = tf.transpose(tf.convert_to_tensor(target, dtype=np.float32))\n",
    "\n",
    "        inputs = [self.pi0_1_4Mom, self.pi_1_4Mom, self.pi0_2_4Mom, self.pi_2_4Mom]\n",
    "        x = tf.convert_to_tensor(inputs, dtype=np.float32)\n",
    "        x = tf.transpose(x, [2, 0, 1])\n",
    "        \n",
    "        k = tf.convert_to_tensor([\n",
    "                          self.impact_param_1[0], self.impact_param_1[1], self.impact_param_1[2], self.impact_param_1[3],\n",
    "                          #self.pi0_1_4Mom[0], self.pi0_1_4Mom[1], self.pi0_1_4Mom[2], self.pi0_1_4Mom[3],\n",
    "                          self.pi_1_4Mom[0], self.pi_1_4Mom[1], self.pi_1_4Mom[2], self.pi_1_4Mom[3],\n",
    "                          #self.pi0_2_4Mom[0], self.pi0_2_4Mom[1], self.pi0_2_4Mom[2], self.pi0_2_4Mom[3],\n",
    "                          self.impact_param_2[0], self.impact_param_2[1], self.impact_param_2[2], self.impact_param_2[3],\n",
    "                          self.pi_2_4Mom[0], self.pi_2_4Mom[1], self.pi_2_4Mom[2], self.pi_2_4Mom[3]],\n",
    "                         dtype=np.float32)\n",
    "\n",
    "# the extra info we are giving\n",
    "        l = tf.convert_to_tensor([self.y_T], dtype=np.float32)\n",
    "\n",
    "        return x,y,k,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print (len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_1 = nu_1 + tau_1_vis\n",
    "tau_2 = nu_2 + tau_2_vis\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tau_1.m,  bins = 1000, alpha = 0.5, label = 'dot product |tau_1_vis| and |nu_1|\\nmean=%.2f, std=%.2f'% (np.array(tau_1.m).mean(), np.array(tau_1.m).std()))\n",
    "plt.hist(np.array(tau_2.m),  bins = 1000, alpha = 0.5, label = 'dot product |tau_2_vis| and |nu_2|\\nmean=%.2f, std=%.2f'% (np.array(tau_2.m).mean(), np.array(tau_2.m).std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(0,6)\n",
    "plt.ylabel('Occurencies', fontsize = 'x-large')\n",
    "plt.xlabel('Mass of sum of rho decay products and tau neutrino', fontsize = 'large')\n",
    "plt.title('Checking that tau neutrino and visible decay products\\nsum up to tau (RM9999)', fontsize = 'xx-large', weight = 'bold')\n",
    "#plt.show()\n",
    "plt.savefig('sum_to_tau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-71f6fbb4e571>:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n"
     ]
    }
   ],
   "source": [
    "Higgs = tau_1 + tau_2 \n",
    "plt.figure()\n",
    "plt.hist(Higgs.m,  bins = 1000, alpha = 0.5, label = 'dot product |tau_1_vis| and |nu_1|\\nmean=%.2f, std=%.2f'% (np.array(Higgs.m).mean(), np.array(Higgs.m).std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.xlim(0,6)\n",
    "plt.ylabel('Occurencies', fontsize = 'x-large')\n",
    "plt.xlabel('Mass of the sum of the two taus', fontsize = 'large')\n",
    "plt.title('Checking that the two taus\\nsum up to Higgs (RM9999)', fontsize = 'xx-large', weight = 'bold')\n",
    "#plt.show()\n",
    "plt.savefig('sum_to_Higgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99919824 0.99922621 0.99976824 ... 0.99905886 0.99952941 0.99982143]\n",
      "[0.99770581 0.99983855 0.99924261 0.98171425 0.9989211  0.99978589\n",
      " 0.99934793 0.99860659 0.99942672 0.99745414]\n"
     ]
    }
   ],
   "source": [
    "#check of the colinearity approximation\n",
    "\n",
    "#Next up: colinarity, tau mass (Kingsley checked) and then Higgs. \n",
    "\n",
    "dot_prod_1 = np.einsum('ia,ia->a',tau_1_vis[1:, ...], nu_1[1:, ...])\n",
    "dot_prod_1 = dot_prod_1/(norm(tau_1_vis[1:, ...])* norm(nu_1[1:, ...]))\n",
    "\n",
    "dot_prod_2 = np.einsum('ia,ia->a',tau_2_vis[1:, ...], nu_2[1:, ...])\n",
    "dot_prod_2 = dot_prod_2/(norm(tau_2_vis[1:, ...])* norm(nu_2[1:, ...]))\n",
    "\n",
    "print(dot_prod_1)\n",
    "print(dot_prod_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(dot_prod_1,  bins = 1000, alpha = 0.5, label = 'dot product |tau_1_vis| and |nu_1|\\nmean=%.2f, std=%.2f'% (dot_prod_1.mean(), dot_prod_1.std()))\n",
    "plt.hist(dot_prod_2,  bins = 1000, alpha = 0.5, label = 'dot product |tau_2_vis| and |nu_2|\\nmean=%.2f, std=%.2f'% (dot_prod_2.mean(), dot_prod_2.std()))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(0.95,1.05)\n",
    "plt.ylabel('Occurencies', fontsize = 'x-large')\n",
    "plt.xlabel('Dot product between rho decay products and tau neutrino', fontsize = 'large')\n",
    "plt.title('Checking the colinarity approximation between\\ntau neutrino and visible decay products', fontsize = 'xx-large', weight = 'bold')\n",
    "\n",
    "plt.savefig('Colinearity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the colinear approximation ? can calculate the dot product between the visible decay products and the nus\n",
    "check_x_1 = np.array(nu_1.p_x-tau_1_vis.p_x)#dot_product(tau_1_vis[1:]/norm(tau_1_vis[1:]), nu_1[1:]/norm(nu_1[1:])))\n",
    "check_x_2 = np.array(nu_2.p_x-tau_2_vis.p_x)#dot_product(tau_2_vis[1:]/norm(tau_2_vis[1:]), nu_2[1:]/norm(nu_2[1:])))\n",
    "check_y_1 = np.array(nu_1.p_y-tau_1_vis.p_y)\n",
    "check_y_2 = np.array(nu_2.p_y-tau_2_vis.p_y)\n",
    "\n",
    "\n",
    "check_z_1 = []\n",
    "check_z_2 = []\n",
    "\n",
    "for i in range (len(nu_1.p_z)):\n",
    "    if nu_1.p_z[i] != 9999:\n",
    "        check_z_1.append(nu_1.p_z[i]-tau_1_vis.p_z[i])\n",
    "    if nu_2.p_z[i] != 9999:\n",
    "        check_z_2.append(nu_2.p_z[i]-tau_2_vis.p_z[i])\n",
    "\n",
    "check_z_1 = np.array(check_z_1)\n",
    "check_z_2 = np.array(check_z_2)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tau_1_vis.p_x - nu_1.p_x, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_1_vis_px and nu_1_px\\nmean=%.2f, std=%.2f'% (check_x_1.mean(),check_x_1.std()))\n",
    "plt.hist(tau_2_vis.p_x - nu_2.p_x, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_2_vis_px and nu_2_px\\nmean=%.2f, std=%.2f'% (check_x_2.mean(),check_x_2.std()))\n",
    "\n",
    "plt.title('Sanity check - difference between \\nsum(pions) and neutrino momenta components', fontsize = 'xx-large', weight = 'bold')\n",
    "plt.xlabel('Difference between momenta components', fontsize = 'x-large')\n",
    "plt.ylabel('Frequency', fontsize = 'x-large')\n",
    "plt.grid()\n",
    "plt.xlim(-250,250)\n",
    "plt.legend()\n",
    "plt.savefig('Check_angles_remove_x')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(tau_1_vis.p_y - nu_1.p_y, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_1_vis_py and nu_1_py\\nmean=%.2f, std=%.2f'% (check_y_1.mean(),check_y_1.std()))\n",
    "plt.hist(tau_2_vis.p_y - nu_2.p_y, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_2_vis_py and nu_2_py\\nmean=%.2f, std=%.2f'% (check_y_2.mean(),check_y_2.std()))\n",
    "plt.title('Sanity check - difference between \\nsum(pions) and neutrino momenta components', fontsize = 'xx-large', weight = 'bold')\n",
    "plt.xlabel('Difference between momenta components', fontsize = 'x-large')\n",
    "plt.ylabel('Frequency', fontsize = 'x-large')\n",
    "plt.grid()\n",
    "plt.xlim(-250,250)\n",
    "plt.legend()\n",
    "plt.savefig('Check_angles_remove_y')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(check_z_1, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_1_vis_pz and nu_1_pz\\nREMOVE 9999 mean=%.2f, std=%.2f'% (check_z_1.mean(),check_z_1.std()))\n",
    "plt.hist(check_z_2, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_2_vis_pz and nu_2_pz\\nREMOVE 9999 mean=%.2f, std=%.2f'% (check_z_2.mean(),check_z_2.std()))\n",
    "\n",
    "\n",
    "plt.title('Sanity check - difference between \\nsum(pions) and neutrino momenta components', fontsize = 'xx-large', weight = 'bold')\n",
    "plt.xlabel('Difference between momenta components', fontsize = 'x-large')\n",
    "plt.ylabel('Frequency', fontsize = 'x-large')\n",
    "plt.grid()\n",
    "plt.xlim(-250,250)\n",
    "plt.legend()\n",
    "plt.savefig('Check_angles_remove_z')\n",
    "\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_E_1 = []#dot_product(tau_1_vis[1:]/norm(tau_1_vis[1:]), nu_1[1:]/norm(nu_1[1:])))\n",
    "check_E_2 = []#dot_product(tau_2_vis[1:]/norm(tau_2_vis[1:]), nu_2[1:]/norm(nu_2[1:])))\n",
    "\n",
    "for i in range (len(nu_1.e)):\n",
    "    if nu_1.e[i]!=9999:\n",
    "        check_E_1.append(nu_1.e[i]-tau_1_vis.e[i])\n",
    "    if nu_2.e[i]!=9999:\n",
    "        check_E_2.append(nu_2.e[i]-tau_2_vis.e[i])\n",
    "\n",
    "check_E_1 = np.array(check_E_1)\n",
    "check_E_2 = np.array(check_E_2)\n",
    "plt.figure()\n",
    "plt.hist(check_E_1, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_1_vis_E and nu_1_E\\nREMOVE 9999 mean=%.2f, std=%.2f'% (check_E_1.mean(),check_E_1.std()))\n",
    "plt.hist(check_E_2, bins = 1000, alpha = 0.5, \n",
    "         label = 'Difference between tau_2_vis_E and nu_2_E\\nREMOVE 9999 mean=%.2f, std=%.2f'% (check_E_2.mean(),check_E_2.std()))\n",
    "\n",
    "\n",
    "plt.title('Sanity check - difference between \\nsum(pions) and neutrino energy components', fontsize = 'xx-large', weight = 'bold')\n",
    "plt.xlabel('Difference between energies', fontsize = 'x-large')\n",
    "plt.ylabel('Frequency', fontsize = 'x-large')\n",
    "plt.grid()\n",
    "plt.xlim(-500,500)\n",
    "plt.legend()\n",
    "plt.savefig('Check_energies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-75e86c0dc241>:29: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig('Compare_nu_E_to_met')\n"
     ]
    }
   ],
   "source": [
    "sum_nu = nu_1 + nu_2\n",
    "\n",
    "met = np.array(df4[\"met\"])\n",
    "sum_energies=[]\n",
    "met_ref = []\n",
    "x = [0,500]\n",
    "\n",
    "for i in range (len(nu_1.e)):\n",
    "    if nu_1.e[i]!=9999 and nu_2.e[i]!=9999:\n",
    "        sum_energies.append(sum_nu.e[i])\n",
    "        met_ref.append(met[i])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(met_ref, sum_energies, 'gx')\n",
    "plt.plot(x,x, 'k--', label = 'y=x')\n",
    "plt.xlabel(\"Missing transverse energy\", fontsize = 'x-large')\n",
    "plt.ylabel(\"Energy of the sum of the neutrinos\", fontsize = 'x-large')\n",
    "plt.title(\"Sanity check, removing 9999 \\n gen level nu energies and met\", fontsize = 'xx-large', weight = 'bold')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(0,500)\n",
    "plt.savefig('Compare_nu_E_to_met')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-d78cf37700c1>:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n"
     ]
    }
   ],
   "source": [
    "x_ref = np.array([0, 6])\n",
    "x_ref2 = [6,0]\n",
    "\n",
    "gen_phitt = np.array(df4[\"gen_phitt\"][:2000])*2*np.pi/180+np.pi\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_ref, x_ref, '--', label = 'x=y')\n",
    "plt.plot(x_ref, x_ref2, '--', label = 'y=-x')\n",
    "\n",
    "plt.hist2d(df4[\"aco_angle_1\"], df4[\"gen_phitt\"], bins=50)\n",
    "#plt.plot(df4[\"aco_angle_1\"][:2000], gen_phitt, 'bx', label='aco_angle_1')\n",
    "#plt.plot(df4[\"aco_angle_5\"][:100], gen_phitt, 'gx', label='aco_angle_5')\n",
    "#plt.plot(df4[\"aco_angle_6\"][:100], gen_phitt, 'rx', label='aco_angle_6')\n",
    "#plt.plot(df4[\"aco_angle_7\"][:100], gen_phitt, 'kx', label='aco_angle_7')\n",
    "#plt.xlabel(\"aco_angles\", fontsize = 'x-large')\n",
    "#plt.ylabel(\"gen_phitt, (rad & shifted)\", fontsize = 'x-large')\n",
    "plt.title(\"Sanity check,\\n gen_phitt against aco angles\", fontsize = 'xx-large', weight = 'bold')\n",
    "#plt.grid()\n",
    "#plt.legend()\n",
    "plt.savefig('Gen_phitt-aco_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN, no custom loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.close()\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(10,10), frameon = True)\n",
    "\n",
    "plt.title('Quality check: 300-300-300-o,\\n Only regress phi Batch: 500')\n",
    "#ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "hist1 = np.array(model({\"lab_frame\": x})[:, 0])\n",
    "hist2 = np.array(y[:, 0])\n",
    "hist_a = hist2-hist1\n",
    "plt.hist(hist_a, bins = 1000, alpha = 0.5,label = \"True-Regressed nu_phi_1\\nMean: %.2f, std: %.2f\"%(hist_a.mean(), hist_a.std()))\n",
    "\n",
    "# hist1 = np.array(model({\"lab_frame\": x})[:, 1])\n",
    "# hist2 = np.array(y[:, 1])\n",
    "# hist_b = hist2-hist1\n",
    "# plt.hist(hist_b, bins = 1000, alpha = 0.5,label = \"True-Regressed nu_phi_2\\nMean: %.2f, std: %.2f\"%(hist_b.mean(), hist_b.std()))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(-2,2)\n",
    "plt.ylabel('Occurences')\n",
    "plt.xlabel('Difference in phi')\n",
    "\n",
    "plt.savefig('Regress_only_phi_C4.png')\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find all the tranings with the custom loss function and the full 4 vector of the neutrinos, here for book keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(968192,), dtype=float32, numpy=\n",
       "array([51.463295, 61.751213, 80.776825, ..., 44.725338, 57.42529 ,\n",
       "       80.36569 ], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mom4_to_tf(tau_1_vis.e) - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here start checking the colinearity method\n",
    "\n",
    "#first verify the spread of phi_nu compared to phi_vis\n",
    "hist = np.array(nu_1.phi - tau_1_vis.phi)\n",
    "hist1 = np.array(nu_2.phi - tau_2_vis.phi)\n",
    "\n",
    "plt.close()\n",
    "plt.close()\n",
    "plt.figure()\n",
    "plt.hist(hist, bins = 1000, alpha=0.5, label = 'Difefrence between nu_phi_1 and vis_phi_1\\nMean:%.2f, Std:%.2f'%(hist.mean(), hist.std()))\n",
    "plt.hist(hist1, bins = 1000, alpha=0.5, label = 'Difefrence between nu_phi_2 and vis_phi_2\\nMean:%.2f, Std:%.2f'%(hist1.mean(), hist1.std()))\n",
    "plt.legend()\n",
    "plt.xlim(-1,1)\n",
    "plt.grid()\n",
    "plt.ylabel('Occurencies')\n",
    "plt.title('Check for phi')\n",
    "plt.xlabel('nu_phi - vis_phi')\n",
    "plt.savefig('Diff_nu_vis_phi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5219455b4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtau_mass_dist_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c5219455b4fa>\u001b[0m in \u001b[0;36mtau_mass_dist_1\u001b[0;34m(y, y_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msum_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_1_vis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_1_vis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msum_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_1_vis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    507\u001b[0m   \"\"\"\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6164\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6166\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6168\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ICMasters/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "#quadratic distance to target - regress both at the same time, will be required for making sense out of the met\n",
    "\n",
    "#try to first work with aplha, only 1 variable - easier\n",
    "# y_1 is the first regressed value, I want them as [[],[]]\n",
    "#D_target = (apha_1 - y_1)**2 + (apha_2 - y_2)**2 \n",
    "\n",
    "def tau_mass_dist_1(y, y_pred):\n",
    "    global tau_1_vis  \n",
    "    \n",
    "    y = tf.transpose(y)\n",
    "    y_pred = tf.transpose(y_pred)\n",
    "    \n",
    "    \n",
    "    sum_energy = tf.transpose(tf.convert_to_tensor(tau_1_vis.e, dtype = 'float32'))+ tf.transpose(y_pred)[0] * tf.transpose(tf.convert_to_tensor(tau_1_vis.p, dtype = 'float32'))\n",
    "    \n",
    "    sum_p = (1+ tf.transpose(y_pred)[0]) * tf.transpose(tf.convert_to_tensor(tau_1_vis.p, dtype = 'float32'))\n",
    "    \n",
    "    \n",
    "    sum_energy_1 = tf.transpose(tf.convert_to_tensor(tau_1_vis.e, dtype = 'float32'))+ y[0] * tf.transpose(tf.convert_to_tensor(tau_1_vis.p, dtype = 'float32'))\n",
    "    \n",
    "    sum_p_1 = (1+ tf.transpose(y[0])) * tf.transpose(tf.convert_to_tensor(tau_1_vis.p, dtype = 'float32'))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    m_tau =  tf.transpose(tf.convert_to_tensor(np.ones(sum_p.shape) * 1.77, dtype = 'float32')) \n",
    "    \n",
    "    return tf.math.abs(sum_energy_1 + sum_energy)#tf.math.abs(sum_energy**2 - sum_p**2 - m_tau**2)  #tf.math.mod(sum_energy**2 - sum_p**2 - m_tau**2)\n",
    "\n",
    "\n",
    "def loss_fn(y, y_pred):\n",
    "#     y = tf.transpose(y)\n",
    "#     y_pred = tf.transpose(y_pred)\n",
    "    return tf.convert_to_tensor((y[0] - y_pred[0])**2 + (y[1] - y_pred[1])**2 + tau_mass_dist_1(y, y_pred))#, dtype = np.float32)\n",
    "\n",
    "\n",
    "#sum_energy**2 - sum_p**2 -\n",
    "\n",
    "# + y[1] * tf.convert_to_tensor(tau_2_vis.p)\n",
    "    \n",
    "    \n",
    "\n",
    "print (tau_mass_dist_1([alpha_1, alpha_2],[alpha_1, alpha_2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
