{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we will train 2 BDTs to differentiate between a CP-even and a CP-odd Higgs for the rhorho channel\n",
    "# One BDT will use only 1 variable analogous to current methodology, the second BDT will include additional information\n",
    "# to help improve the seperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Jupyter Notebook I will use for the Master's project, it is based on Example 1 also available in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uproot in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (3.10.12)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (1.16.4)\n",
      "Requirement already satisfied: awkward<1.0,>=0.12.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (0.12.17)\n",
      "Requirement already satisfied: uproot-methods>=0.7.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (0.7.1)\n",
      "Requirement already satisfied: cachetools in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user uproot\n",
    "import sys\n",
    "sys.path.append(\"/eos/home-m/acraplet/.local/lib/python2.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tree\n",
    "tree = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GluGluHToTauTauUncorrelatedDecay_Filtered_tt_2018.root\")[\"ntuple\"]\n",
    "tree2 = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_VBFHToTauTauUncorrelatedDecay_Filtered_tt_2018.root\")[\"ntuple\"]\n",
    "\n",
    "\n",
    "#These are new trees, added by Danny on 13/10\n",
    "tree3=uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_AllHiggs_tt.root\")[\"ntuple\"]  \n",
    "#note, instead of the first t we can have e,m, different decay modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what variables are to be read into the dataframe\n",
    "\n",
    "variables = [  \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\",\n",
    "                \"rand\",\n",
    "                \"pt_1\",\"pt_2\",\n",
    "                \"met\",\n",
    "                \"aco_angle_1\", \"aco_angle_5\", \"aco_angle_7\", \"aco_angle_6\",\n",
    "                \"y_1_1\", \"y_1_2\",\n",
    "                \"ip_sig_1\", \"ip_sig_2\",\n",
    "                \"mva_dm_1\",\"mva_dm_2\",\n",
    "                \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "                \"deepTauVsJets_medium_1\",\"deepTauVsJets_medium_2\",\n",
    "                \"deepTauVsEle_vvloose_1\",\"deepTauVsEle_vvloose_2\",\n",
    "                \"deepTauVsMu_vloose_1\",\"deepTauVsMu_vloose_2\",\n",
    "                \"trg_doubletau\",\n",
    "             ]\n",
    "\n",
    "df = tree.pandas.df(variables)\n",
    "\n",
    "df2 = tree2.pandas.df(variables)\n",
    "\n",
    "#tree3 should be more comprehensive and complete as it includes all decay types and more\n",
    "#info for tau->a1 decays. Again we save the same variables for now\n",
    "\n",
    "#df3 = tree3.pandas.df(variables)\n",
    "\n",
    "#combine VBF and ggH events\n",
    "\n",
    "df = pd.concat([df,df2], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep working on the first tree for now (because everything is set up for it but in the future it'll be useful to look at the other ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply some preselections, these selections are used to mimic those used \n",
    "#in the analysis and to select only rhorho events\n",
    "# also use random number \"rand\" and tau spinner weights \"wt_cp_{sm,ps,mm}\" \n",
    "#to select a sample of CP-even and CP-odd\n",
    "# like events. the weights go beween 0 and 2 so by dividing by 2 \n",
    "#we can interpret these as probabilities and select\n",
    "# CP-even(odd) events if the rand is less than this probability \n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(123456)\n",
    "\n",
    "df_1 = df[\n",
    "      (df[\"tau_decay_mode_1\"] == 1) \n",
    "    & (df[\"tau_decay_mode_2\"] == 1) \n",
    "    & (df[\"mva_dm_1\"] == 1) \n",
    "    & (df[\"mva_dm_2\"] == 1)\n",
    "    # comment some selections to help with stats\n",
    "    #& (df[\"deepTauVsJets_medium_1\"] > 0.5) \n",
    "    #& (df[\"deepTauVsEle_vvloose_1\"] > 0.5)\n",
    "    #& (df[\"deepTauVsMu_vloose_1\"] > 0.5)\n",
    "    #& (df[\"deepTauVsJets_medium_2\"] > 0.5) \n",
    "    #& (df[\"deepTauVsEle_vvloose_2\"] > 0.5)\n",
    "    #& (df[\"deepTauVsMu_vloose_2\"] > 0.5)\n",
    "    #& (df[\"trg_doubletau\"] > 0.5)\n",
    "]\n",
    "\n",
    "df_ps = df_1[\n",
    "      (df_1[\"rand\"]<df_1[\"wt_cp_ps\"]/2)     #a data frame only including the pseudoscalars\n",
    "]\n",
    "\n",
    "df_sm = df_1[\n",
    "      (df_1[\"rand\"]<df_1[\"wt_cp_sm\"]/2)     #data frame only including the scalars\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create target labels (y)\n",
    "         \n",
    "# prepare the target labels\n",
    "y_sm = pd.DataFrame(np.ones(df_sm.shape[0]))\n",
    "y_ps = pd.DataFrame(np.zeros(df_ps.shape[0]))\n",
    "\n",
    "y = pd.concat([y_sm, y_ps])  #is this just about having the right shape ?\n",
    "y.columns = [\"class\"]\n",
    "\n",
    "# prepare the dataframe to use in training\n",
    "X = pd.concat([df_sm, df_ps])\n",
    "\n",
    "# drop any other variables that aren't required in training\n",
    "\n",
    "X2 = X.drop([\n",
    "            \"wt_cp_sm\",\"wt_cp_ps\",\"wt_cp_mm\", \"rand\",\n",
    "            \"tau_decay_mode_1\",\"tau_decay_mode_2\",\"mva_dm_1\",\"mva_dm_2\",\n",
    "            \"deepTauVsJets_medium_1\",\"deepTauVsJets_medium_2\",\n",
    "            \"deepTauVsEle_vvloose_1\",\"deepTauVsEle_vvloose_2\",\n",
    "            \"deepTauVsMu_vloose_1\",\"deepTauVsMu_vloose_2\",\n",
    "            \"trg_doubletau\",\n",
    "           ], axis=1).reset_index(drop=True) \n",
    "\n",
    "# now we create a seperate version of X where we drop all variables except for aco_angle_1 \n",
    "# which is the most sensitive simple variable\n",
    "\n",
    "X1 = X2.drop(X2.columns.difference([\"aco_angle_1\"]), axis=1).reset_index(drop=True) \n",
    "\n",
    "\n",
    "#how do we print the dimensions of a panda object ? I would like to see if we indeed only\n",
    "#have 'aco_angle_1' on the X1 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot 'signal' vs 'background' for a specified variables\n",
    "# useful to check whether a variable gives some separation between\n",
    "# signal and background states\n",
    "def plot_signal_background(data1, data2, column,\n",
    "                        bins=100, x_uplim=0, **kwargs):\n",
    "\n",
    "    if \"alpha\" not in kwargs:  #just setting the transparency of columns\n",
    "        kwargs[\"alpha\"] = 0.5\n",
    "\n",
    "    df1 = data1[column]\n",
    "    df2 = data2[column]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df1 = df1.sample(3000, random_state=1234)   #we only take 3000 points\n",
    "    df2 = df2.sample(3000, random_state=1234)\n",
    "    low = max(min(df1.min(), df2.min()),-5)     \n",
    "    high = max(df1.max(), df2.max())\n",
    "    \n",
    "    if x_uplim != 0: high = x_uplim #you can choose where you plot from\n",
    "\n",
    "    ax.hist(df1, bins=bins, range=(low,high), **kwargs,label='Data1')\n",
    "    ax.hist(df2, bins=bins, range=(low,high), **kwargs,label='Data2')\n",
    "    \n",
    "    if x_uplim != 0:\n",
    "        ax.set_xlim(0,x_uplim)\n",
    "        \n",
    "    plt.title('Difference between data 1 and data 2 for variable %s'%column,weight='bold')\n",
    "    plt.xlabel('%s'%key)\n",
    "    plt.ylabel('Occurences out of 3000')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make plots of all variables\n",
    "\n",
    "for key, values in X2.iteritems():\n",
    "    #print(key)\n",
    "    plot_signal_background(df_ps, df_sm, key, bins=100)\n",
    "\n",
    "plt.savefig('Ps_SM_sig_bck_%s.png'%key) #put in the loop to have everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Calculate the acoplanary angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any traning, let's try and reconstruct aco_angle_1 from the low level variable. \n",
    "$\\mathbf{\\lambda}^{\\pm}=(0,\\mathbf{j}^\\pm)$ where $\\mathbf{j}^\\pm$ is the impact parameter vector defined as the vector btw the primary vertex (PV) and the point of closest approach (PCA).\n",
    "\n",
    "Then we need to boost $\\mathbf{\\lambda}^{\\pm}$ into the zero momentum frame (ZMF) thus giving $\\mathbf{\\lambda}^{*\\pm}$. I will need to code a function to boost any four vector into the pion's ZMF. \n",
    "\n",
    "We will also need $\\mathbf{q}^{*\\pm}$ are the four-vector for charged pions, boosted in the ZMF. \n",
    "\n",
    "After that we will calculate $\\mathbf{\\lambda}^{*\\pm}_{\\perp}$ the transverse component of $\\mathbf{\\lambda}^{*\\pm}$ w.r.t. $\\mathbf{q}^{*\\pm}$. \n",
    "\n",
    "Finally, the acoplanary angle $\\phi_{CP}$ is definied by \n",
    "\n",
    "$\\phi_{\\mathrm{CP}}=\\left\\{\\begin{array}{ll} \\phi^{*} &  \\text { if } O^{*} \\geq 0 \\\\  360^{\\circ}-\\phi^{*} & \\text { if } O^{*}<0 \\end{array}\\right\\}$\n",
    "\n",
    "with $O^{*}=\\hat{q}^{*-} \\cdot\\left(\\hat{\\lambda}_{\\perp}^{*+} \\times \\hat{\\lambda}_{\\perp}^{*-}\\right)$.\n",
    "\n",
    "\n",
    "Start with $\\mathbf{j}^\\pm$, check what we have in terms of available informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The impact parameter vector for the leading and sub-leading are given by ip_{x,y,z}_{1,2}\n",
    "\n",
    "#ip_sig_{1,2} gives the significance of the impact paramter, will be usefull in future.\n",
    "\n",
    "#Now define a new panda dataframe, which I'll only use to get out the acoplanary angle\n",
    "#using low level variables (maybe we'll need to reconstruct the impact parameter vector \n",
    "#as well but I don't think that this is usefull just yet).\n",
    "\n",
    "variables4 = [\"ip_x_1\",\"ip_y_1\",\"ip_z_1\",\n",
    "              \"ip_x_2\",\"ip_y_2\",\"ip_z_2\",\n",
    "              \"aco_angle_1\", \n",
    "              \"pi_E_1\",\"pi_px_1\",\"pi_py_1\",\"pi_pz_1\",\n",
    "              \"pi_E_2\",\"pi_px_2\",\"pi_py_2\",\"pi_pz_2\",\n",
    "              \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "              \"mva_dm_1\",\"mva_dm_2\",\n",
    "              \"pi0_E_1\",\"pi0_px_1\",\"pi0_py_1\",\"pi0_pz_1\",\n",
    "              \"pi0_E_2\",\"pi0_px_2\",\"pi0_py_2\",\"pi0_pz_2\"\n",
    "              \n",
    "             ]\n",
    "\n",
    "\n",
    "df4 = tree.pandas.df(variables4)\n",
    "\n",
    "df4 = df4[\n",
    "      (df4[\"tau_decay_mode_1\"] == 1) \n",
    "    & (df4[\"tau_decay_mode_2\"] == 1) \n",
    "    & (df4[\"mva_dm_1\"] == 1) \n",
    "    & (df4[\"mva_dm_2\"] == 1)\n",
    "]\n",
    "\n",
    "#keep that ??    \n",
    "\n",
    "#note: maybe we'll have to apply some cuts, to not get the a1 for example whose \n",
    "# decays are more complicated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pylorentz in /eos/home-a/acraplet/.local/lib/python3.7/site-packages (0.3.3)\r\n",
      "Requirement already satisfied: numpy in /cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from pylorentz) (1.16.4)\r\n"
     ]
    }
   ],
   "source": [
    "#Let's try and use the pylorentz module for performing boosts\n",
    "# more info: https://gitlab.sauerburger.com/frank/pylorentz/-/blob/master/pylorentz/__init__.py\n",
    "\n",
    "!pip install --user pylorentz\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Vector4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The unboosted impact paramter four vector for the leading and subleading e,m or t\n",
    "\n",
    "#df4[\"lamda_pm_1\"]=pd.Series([pd.Series(np.zeros(len(df4['ip_x_1']))),df4['ip_x_1'],df4['ip_y_1'],df4['ip_z_1']])\n",
    "#df4[\"lamda_pm_2\"]=pd.Series([pd.Series(np.zeros(len(df4['ip_x_2']))),df4['ip_x_2'],df4['ip_y_2'],df4['ip_z_2']])\n",
    "\n",
    "\n",
    "ip_1_4Vect=Vector4(pd.Series(np.zeros(len(df4['ip_x_1']))),df4['ip_x_1'],df4['ip_y_1'],df4['ip_z_1'])\n",
    "ip_2_4Vect=Vector4(pd.Series(np.zeros(len(df4['ip_x_2']))),df4['ip_x_2'],df4['ip_y_2'],df4['ip_z_2'])\n",
    "\n",
    "pi_1_4Vect=Vector4(df4[\"pi_E_1\"],df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"])\n",
    "pi_2_4Vect=Vector4(df4[\"pi_E_2\"],df4[\"pi_px_2\"],df4[\"pi_py_2\"],df4[\"pi_pz_2\"])\n",
    "\n",
    "\n",
    "pi0_1_4Vect=Vector4(df4[\"pi0_E_1\"],df4[\"pi0_px_1\"],df4[\"pi0_py_1\"],df4[\"pi0_pz_1\"])\n",
    "pi0_2_4Vect=Vector4(df4[\"pi0_E_2\"],df4[\"pi0_px_2\"],df4[\"pi0_py_2\"],df4[\"pi0_pz_2\"])\n",
    "# we have transverse momentum of leading and subleading e,m,t in pT_{1,2}\n",
    "\n",
    "#Need to convert the 4 Vector into a 4 momenta ?\n",
    "pi_1_4Mom=Momentum4(pi_1_4Vect)\n",
    "pi_2_4Mom=Momentum4(pi_2_4Vect)\n",
    "\n",
    "#Same for the pi0\n",
    "pi0_1_4Mom=Momentum4(pi0_1_4Vect)\n",
    "pi0_2_4Mom=Momentum4(pi0_2_4Vect)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulus_nVector(nVector):\n",
    "    #calulate the modulus of any vector\n",
    "    if len(nVector)==4:\n",
    "        print('Careful, this is not the appropriate way to calculate the modulus of a 4vector')\n",
    "    sum_squares_all=[]\n",
    "    for j in range(len(nVector[0])):\n",
    "        sum_squares=0\n",
    "        for i in range(len(nVector)):\n",
    "            sum_squares=sum_squares+nVector[i][j]**2\n",
    "        sum_squares_all.append(sum_squares)\n",
    "    sum_squares_all=np.array(sum_squares_all)\n",
    "    return np.sqrt(sum_squares_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vector1,vector2):\n",
    "    if len(vector1)!=len(vector2):\n",
    "        raise Arrays_of_different_size\n",
    "    prod=0\n",
    "    for i in range(len(vector1)):\n",
    "        prod=prod+vector1[i]*vector2[i]\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lorentz_boost_ZMF(four_vector,v_COM_3vector,c=500): #change this c !!\n",
    "    #a function to calculate the value of any vector in the ZMF frame, based on:\n",
    "    #https://en.wikipedia.org/wiki/Lorentz_transformation#Vector_transformations\n",
    "    \n",
    "    A=four_vector[0]\n",
    "    Z_x=four_vector[1]\n",
    "    Z_y=four_vector[2]\n",
    "    Z_z=four_vector[3]\n",
    "    \n",
    "    Z_3vector=np.array([Z_x,Z_y,Z_z])\n",
    "    \n",
    "    v_COM_3vector=np.array(v_COM_3vector)\n",
    "    n=np.array(v_COM_3vector/modulus_nVector(v_COM_3vector))\n",
    "    \n",
    "    beta_3vector=v_COM_3vector/c\n",
    "    beta=beta_3vector/modulus_nVector(beta_3vector)\n",
    "    gamma=1/np.sqrt(1-modulus_nVector(beta_3vector)**2)\n",
    "    \n",
    "    A_prime=gamma*(A-dot_product(v_COM_3vector,Z_3vector))\n",
    "    Z_3vector_prime=Z_3vector+(gamma-1)/modulus_nVector(v_COM_3vector)**2*dot_product(Z_3vector,v_COM_3vector)*beta_3vector-gamma*A*v_COM_3vector\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #look at https://root.cern/root/html530/TLorentzVector.html for help\n",
    "    \n",
    "    return np.array([A_prime,Z_3vector_prime[0],Z_3vector_prime[1],Z_3vector_prime[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01946761 0.01946761 0.01946761 ... 0.01946761 0.01946761 0.01946761]\n",
      "[0.13952637 0.13952637 0.13952637 ... 0.13952637 0.13952637 0.13952637]\n",
      "entry\n",
      "4           187.662168\n",
      "15           28.020788\n",
      "26          146.129760\n",
      "39           32.468280\n",
      "55          558.524720\n",
      "56          520.335614\n",
      "58          230.084675\n",
      "61          192.493465\n",
      "77          164.182828\n",
      "92          137.178621\n",
      "106          63.525510\n",
      "107         450.295219\n",
      "112         327.912857\n",
      "126         331.013251\n",
      "127         433.449655\n",
      "129          85.994151\n",
      "144         152.802719\n",
      "164         298.668849\n",
      "171         303.903628\n",
      "184         282.883864\n",
      "187         402.739094\n",
      "191         100.683653\n",
      "200          34.078433\n",
      "222          57.104212\n",
      "229         199.708271\n",
      "232         128.548427\n",
      "245         989.784872\n",
      "268         173.722599\n",
      "277         543.950910\n",
      "282         460.883853\n",
      "              ...     \n",
      "1423313      33.096005\n",
      "1423316     193.437733\n",
      "1423318     498.034407\n",
      "1423351     200.419262\n",
      "1423360    1082.708758\n",
      "1423385     191.721494\n",
      "1423399      77.754256\n",
      "1423404     190.894307\n",
      "1423405      24.245187\n",
      "1423410     284.283615\n",
      "1423414      47.664718\n",
      "1423420     279.109985\n",
      "1423423    1038.262698\n",
      "1423446     620.650244\n",
      "1423472     345.227946\n",
      "1423487     355.592552\n",
      "1423516      99.091468\n",
      "1423518     465.453912\n",
      "1423520      49.280620\n",
      "1423524     671.473121\n",
      "1423528     227.905596\n",
      "1423547     187.746368\n",
      "1423548     464.383380\n",
      "1423550     567.353705\n",
      "1423554     340.008224\n",
      "1423564     872.392585\n",
      "1423574     280.076677\n",
      "1423581     243.528727\n",
      "1423585     457.174961\n",
      "1423588     115.726670\n",
      "Length: 145487, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/start_ipykernel.py:10: RuntimeWarning: invalid value encountered in sqrt\n",
      "/usr/local/bin/start_ipykernel.py:12: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "# Fixing the light speed issue\n",
    "\n",
    "energy=np.array(df4[\"pi_E_1\"])\n",
    "momentum_3vector=np.array([df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"]])\n",
    "\n",
    "m=energy**2-dot_product(momentum_3vector,momentum_3vector)\n",
    "\n",
    "print(energy**2-dot_product(momentum_3vector,momentum_3vector))\n",
    "\n",
    "print(np.sqrt(m))\n",
    "\n",
    "print(np.sqrt(df4[\"pi_px_1\"]**2+df4[\"pi_py_1\"]**2+df4[\"pi_pz_1\"]**2)/(np.sqrt(m)))  #ISSUE !! THIS DOES NOT GIVE 1\n",
    "\n",
    "#so c=1, that makes sense !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/start_ipykernel.py:19: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "#Start over, easier, try to use the py module as little as possible\n",
    "\n",
    "#This should be the velocity of the two pions's pi- and pi0 COM ! Not good !\n",
    "#v_COM_x=np.array(df4[\"pi_px_1\"]+df4[\"pi0_px_1\"])/(pi0_1_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "#v_COM_y=np.array(df4[\"pi_py_1\"]+df4[\"pi0_py_1\"])/(pi0_1_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "#v_COM_z=np.array(df4[\"pi_pz_1\"]+df4[\"pi0_pz_1\"])/(pi0_1_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "\n",
    "#The issue was that I was using the pi0 and pi isntead of the pi- and pi+ frame (which is therefore wrong)\n",
    "v_COM_x=np.array(df4[\"pi_px_1\"]+df4[\"pi_px_2\"])/(pi_2_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "v_COM_y=np.array(df4[\"pi_py_1\"]+df4[\"pi_py_2\"])/(pi_2_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "v_COM_z=np.array(df4[\"pi_pz_1\"]+df4[\"pi_pz_2\"])/(pi_2_4Mom.m[0]+pi_1_4Mom.m[0])\n",
    "#This should be correct\n",
    "\n",
    "#print(pi0_1_4Mom.m) # 0.1349 in GeV/c^2\n",
    "#print(pi_1_4Mom.m) # 0.13952637+0.j\n",
    "\n",
    "p_pi_1=np.array([df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"]])#pi_1_4Mom.m[0]=0.1349 in GeV/c^2\n",
    "\n",
    "gamma=1/np.sqrt(1-(modulus_nVector(p_pi_1)/np.sqrt(m)[0])**2)\n",
    "\n",
    "\n",
    "print(gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(modulus_nVector(v_pi_1).max(),pi_2_4Mom.m[0])\n",
    "\n",
    "v_COM_3vector=np.array([v_COM_x,v_COM_y,v_COM_z])\n",
    "v_mod=modulus_nVector(v_COM_3vector)\n",
    "\n",
    "\n",
    "c=1##v_mod.max()*1.25\n",
    "\n",
    "#is there only an issue with c ?\n",
    "\n",
    "\n",
    "pi_2_4Vect_star=Lorentz_boost_ZMF(pi_2_4Vect,v_COM_3vector,c)\n",
    "pi_1_4Vect_star=Lorentz_boost_ZMF(pi_1_4Vect,v_COM_3vector,c)\n",
    "\n",
    "print(pi_1_4Vect_star[1]-pi_2_4Vect_star[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I was having issues with the velocity of light it should be in GeV? \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for f in range(0,10):\n",
    "    c=v_mod.max()*(1+f/10)\n",
    "    pi2=Lorentz_boost_ZMF(pi_2_4Vect,v_COM_3vector,c)\n",
    "    pi=Lorentz_boost_ZMF(pi_1_4Vect,v_COM_3vector,c)\n",
    "    pi2_mom=np.array([pi2[1],pi2[2],pi2[3]])\n",
    "    pi_mom=np.array([pi[1],pi[2],pi[3]])\n",
    "    \n",
    "    array=np.array(modulus_nVector(pi2_mom)**2-modulus_nVector(pi_mom)**2)\n",
    "\n",
    "    print('Here %f'%f)\n",
    "    plt.plot(c,array.mean(),'bx')\n",
    "\n",
    "plt.ylabel('Mean difference between ${p^{*}_{\\pi^\\pm}}^2$ and ${p^{*}_{\\pi^0}}^2$')\n",
    "plt.xlabel('Value of c(a.u)')\n",
    "plt.grid()\n",
    "plt.savefig('Investigating_c_new.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v_COM_mod=np.sqrt(v_COM_x**2+v_COM_y**2+v_COM_x**2) #what is this unit ?\n",
    "\n",
    "#c=500 #this these units !?\n",
    "\n",
    "#beta_x=v_COM_x/c\n",
    "#beta_y=v_COM_y/c\n",
    "#beta_z=v_COM_z/c\n",
    "\n",
    "#beta_3vect=np.array([beta_x,beta_y,beta_z])\n",
    "#beta_mod=np.sqrt(beta_x**2+beta_y**2+beta_z**2)\n",
    "\n",
    "#print(beta_mod)\n",
    "\n",
    "#gamma=1/np.sqrt(1-beta_mod**2)  #good way to check if we have the wrong c\n",
    "#print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Check the momenta of the pions, are they opposite in the lab frame ?\n",
    "print(pi_1_4Mom.p,pi0_1_4Mom.p) \n",
    "print(pi_2_4Mom.p,pi0_2_4Mom.p) \n",
    "#they are not opposite in the lab frame but we only have rhorho decays... \n",
    "\n",
    "#print(pi_1_4Mom.e[:3])  #The two formulations are identical, that is good\n",
    "#print(pi_1_4Vect[0][:3])\n",
    "\n",
    "#Now try some transforms into the pions ZMF\n",
    "ip_1_4Vect_star=ip_1_4Vect.boost_particle(pi_1_4Mom)\n",
    "ip_2_4Vect_star=ip_2_4Vect.boost_particle(pi_2_4Mom)\n",
    "\n",
    "#print(ip_1_4Vect_star.mag2[3],ip_1_4Vect.mag2[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here some sanity checks \n",
    "check_magnitude_1=[]\n",
    "check_magnitude_2=[]\n",
    "for i in range(10):\n",
    "    check_magnitude_1.append(ip_1_4Vect_star.mag2[i]-ip_1_4Vect.mag2[i])\n",
    "    check_magnitude_2.append(ip_2_4Vect_star.mag2[i]-ip_2_4Vect.mag2[i])\n",
    "\n",
    "\n",
    "check_magnitude_1=np.array(check_magnitude_1)\n",
    "check_magnitude_2=np.array(check_magnitude_2)\n",
    "plt.figure()\n",
    "plt.hist(check_magnitude_1,bins=100,alpha=0.5,\n",
    "         label='Leading: Mean:%.2e,std:%.2e'%(check_magnitude_1.mean(),\n",
    "                                              check_magnitude_1.std()))\n",
    "plt.hist(check_magnitude_2,bins=100,alpha=0.5,\n",
    "         label='Sub-leading: Mean:%.2e,std:%.2e'%(check_magnitude_2.mean(),\n",
    "                                                  check_magnitude_2.std()))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('Occurence')\n",
    "plt.title('Sanity check: magnitude of IP 4Vectors after boost',fontsize='large')\n",
    "plt.xlabel('${\\lambda_{\\pm}^{*}}^2-{\\lambda_{\\pm}}^2$')\n",
    "#plt.savefig(\"Check_magnitude.png\")\n",
    "\n",
    "plt.show()\n",
    "# could also check transverse momentum is good ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, now also check that we are in the pi rest frame, if we transform the pi w.r.t. their\n",
    "# own rest frame we should have 0 momentum ?\n",
    "\n",
    "\n",
    "pi_1_4Vect_star=pi_1_4Vect.boost_particle(pi_1_4Mom)\n",
    "pi_2_4Vect_star=pi_2_4Vect.boost_particle(pi_2_4Mom)\n",
    "\n",
    "print(Momentum4(pi_1_4Vect_star).p[:10],Momentum4(pi_2_4Vect_star).p[:10]) \n",
    "#ok we definitely do not have 0 momentum... why not ?? have we chosen the wrong reference?\n",
    "\n",
    "\n",
    "#could it be that that we want to be in the ZMF frame of the sum of the pions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next thing we'll need: the transverse part of lambda* wrt the boosted 4vector of the\n",
    "#charge pions, Iam a bit confused: isn't the charged pion's boosted momentum just 0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X1, X2, and y into train and validation dataset \n",
    "\n",
    "X1_train,X1_test, y1_train, y1_test  = train_test_split(\n",
    "    X1,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=123456,\n",
    "    stratify=y.values,\n",
    ")\n",
    "\n",
    "X2_train,X2_test, y2_train, y2_test  = train_test_split(\n",
    "    X2,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=123456,\n",
    "    stratify=y.values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some XGBoost parameters, unspecified will be default\n",
    "# https://xgboost.readthedocs.io/en/latest////index.html\n",
    "# not optimised at all, just playing by ear\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"silent\": 1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"subsample\": 0.9,\n",
    "    \"seed\": 123451,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first run the training for simple case with just 1 variable\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_clf.fit(\n",
    "    X1_train,\n",
    "    y1_train,\n",
    "    early_stopping_rounds=200, # stops the training if doesn't improve after 200 iterations\n",
    "    eval_set=[(X1_train, y1_train), (X1_test, y1_test)],\n",
    "    eval_metric = \"auc\", # can use others\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "#xgb_clf.get_booster().save_model('rho_rho.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at feature importance\n",
    "# can use different metrics (weight or gain), look up online\n",
    "xgb.plot_importance(xgb_clf, importance_type='weight')\n",
    "xgb.plot_importance(xgb_clf, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('roc_rho_rho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for improved training\n",
    "y1_proba = xgb_clf.predict_proba(X1_test) # outputs two probabilties\n",
    "\n",
    "auc = roc_auc_score(y1_test, y1_proba[:,1])\n",
    "fpr, tpr, _ = roc_curve(y1_test, y1_proba[:,1])\n",
    "plot_roc_curve(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train with all variables\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_clf.fit(\n",
    "    X2_train,\n",
    "    y2_train,\n",
    "    early_stopping_rounds=200, # stops the training if doesn't improve after 200 iterations\n",
    "    eval_set=[(X2_train, y2_train), (X2_test, y2_test)],\n",
    "    eval_metric = \"auc\", # can use others\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"silent\": 1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"subsample\": 0.9,\n",
    "    \"seed\": 123451,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at feature importance\n",
    "# can use different metrics (weight or gain), look up online\n",
    "xgb.plot_importance(xgb_clf, importance_type='weight')\n",
    "xgb.plot_importance(xgb_clf, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for improved training\n",
    "y2_proba = xgb_clf.predict_proba(X2_test) # outputs two probabilties\n",
    "auc2 = roc_auc_score(y2_test, y2_proba[:,1])\n",
    "fpr2, tpr2, _ = roc_curve(y2_test, y2_proba[:,1])\n",
    "plot_roc_curve(fpr2, tpr2, auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_2_roc_curves(fpr, tpr, auc, fpr2, tpr2, auc2):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.plot(fpr2, tpr2)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    ax.text(0.6, 0.2, 'ROC AUC Score: {:.3f}'.format(auc2),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('roc_rho_rho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot roc curves on same axis\n",
    "plot_2_roc_curves(fpr, tpr, auc, fpr2, tpr2, auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
