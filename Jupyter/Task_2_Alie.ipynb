{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a NN to regress aco_angle_1 - this will give us some ideas about how we need to setup the NN in order for it to make use of the low-level information and then we can use a similar architecture for our final NN setup. After reading around online a bit one possible reason that the NN is not working very well is because the CP observables depend on what rest frame you determine them in and possibly the NN is not well setup to handle Lorentz boosts into different frames. I found a paper which suggest how to setup the first layers of a NN in order to perform such Lorentz boosts (https://arxiv.org/pdf/1812.09722.pdf) - this might be a good place to start, but of course if you have other ideas you are free to follow themSet up a Neural Network to reconstruct the aco_angle_1 from basic variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uproot in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (3.10.12)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (1.18.2)\n",
      "Requirement already satisfied: awkward<1.0,>=0.12.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (0.12.17)\n",
      "Requirement already satisfied: uproot-methods>=0.7.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (0.7.1)\n",
      "Requirement already satisfied: cachetools in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from uproot) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user uproot\n",
    "import sys\n",
    "sys.path.append(\"/eos/home-m/acraplet/.local/lib/python2.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lbn in /eos/home-a/acraplet/.local/lib/python3.7/site-packages (1.2.1)\n",
      "Requirement already satisfied: tensorflow in /eos/home-a/acraplet/.local/lib/python3.7/site-packages (from lbn) (2.3.1)\n",
      "Requirement already satisfied: numpy in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from lbn) (1.18.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (1.28.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (1.11.1)\n",
      "Collecting h5py<2.11.0,>=2.10.0 (from tensorflow->lbn)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: astunparse==1.6.3 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (0.2.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1 (from tensorflow->lbn)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (3.2.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (0.33.4)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (0.7.1)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow->lbn)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting gast==0.3.3 (from tensorflow->lbn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow->lbn) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (44.1.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (1.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (0.15.4)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<3,>=2.3.0->tensorflow->lbn)\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: markdown>=2.6.8 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->lbn) (0.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->lbn) (0.2.5)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->lbn) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->lbn) (3.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->lbn) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->lbn) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->lbn) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->lbn) (2019.3.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->lbn) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->lbn) (0.4.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->lbn) (3.0.1)\n",
      "\u001b[31mERROR: tensorflow-cpu 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: h5py, keras-preprocessing, protobuf, gast, tensorboard-plugin-wit\n",
      "Successfully installed gast-0.3.3 h5py-2.10.0 keras-preprocessing-1.1.2 protobuf-3.13.0 tensorboard-plugin-wit-1.7.0\n",
      "Requirement already satisfied: tensorflow in /eos/home-a/acraplet/.local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py<2.11.0,>=2.10.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting gast==0.3.3 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.12.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.28.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (1.18.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (44.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /eos/home-a/acraplet/.local/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.3.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.5)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3python3/Wed/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.5)\n",
      "\u001b[31mERROR: tensorflow-cpu 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, h5py, gast, protobuf\n",
      "Successfully installed gast-0.3.3 h5py-2.10.0 keras-preprocessing-1.1.2 protobuf-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user lbn\n",
    "!pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from lbn import LBN, LBNLayer\n",
    "import tensorflow as tf\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tree\n",
    "tree = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GluGluHToTauTauUncorrelatedDecay_Filtered_tt_2018.root\")[\"ntuple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what variables are to be read into the dataframe\n",
    "\n",
    "momenta_features = [ \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", #leading charged pi 4-momentum\n",
    "              \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", #subleading charged pi 4-momentum\n",
    "              \"pi0_E_1\",\"pi0_px_1\",\"pi0_py_1\",\"pi0_pz_1\", #leading neutral pi 4-momentum\n",
    "              \"pi0_E_2\",\"pi0_px_2\",\"pi0_py_2\",\"pi0_pz_2\"] #subleading neutral pi 4-momentum\n",
    "\n",
    "other_features = [ \"ip_x_1\", \"ip_y_1\", \"ip_z_1\",        #leading impact parameter\n",
    "                   \"ip_x_2\", \"ip_y_2\", \"ip_z_2\",        #subleading impact parameter\n",
    "                   \"y_1_1\", \"y_1_2\"]    # ratios of energies\n",
    "\n",
    "target = [    \"aco_angle_1\"]  #acoplanarity angle\n",
    "    \n",
    "selectors = [ \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "             \"mva_dm_1\",\"mva_dm_2\",\"rand\",\"wt_cp_ps\",\"wt_cp_sm\",\n",
    "            ]\n",
    "\n",
    "variables4=(momenta_features+other_features+target+selectors) #copying Kinglsey's way cause it is very clean\n",
    "\n",
    "df4 = tree.pandas.df(variables4)\n",
    "\n",
    "df4 = df4[\n",
    "      (df4[\"tau_decay_mode_1\"] == 1) \n",
    "    & (df4[\"tau_decay_mode_2\"] == 1) \n",
    "    & (df4[\"mva_dm_1\"] == 1) \n",
    "    & (df4[\"mva_dm_2\"] == 1)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df_ps = df4[\n",
    "      (df4[\"rand\"]<df4[\"wt_cp_ps\"]/2)     #a data frame only including the pseudoscalars\n",
    "]\n",
    "\n",
    "df_sm = df4[\n",
    "      (df4[\"rand\"]<df4[\"wt_cp_sm\"]/2)     #data frame only including the scalars\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pi_E_1</th>\n",
       "      <th>pi_px_1</th>\n",
       "      <th>pi_py_1</th>\n",
       "      <th>pi_pz_1</th>\n",
       "      <th>pi_E_2</th>\n",
       "      <th>pi_px_2</th>\n",
       "      <th>pi_py_2</th>\n",
       "      <th>pi_pz_2</th>\n",
       "      <th>pi0_E_1</th>\n",
       "      <th>pi0_px_1</th>\n",
       "      <th>...</th>\n",
       "      <th>y_1_1</th>\n",
       "      <th>y_1_2</th>\n",
       "      <th>aco_angle_1</th>\n",
       "      <th>tau_decay_mode_1</th>\n",
       "      <th>tau_decay_mode_2</th>\n",
       "      <th>mva_dm_1</th>\n",
       "      <th>mva_dm_2</th>\n",
       "      <th>rand</th>\n",
       "      <th>wt_cp_ps</th>\n",
       "      <th>wt_cp_sm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.184192</td>\n",
       "      <td>5.249920</td>\n",
       "      <td>-12.394966</td>\n",
       "      <td>-22.458754</td>\n",
       "      <td>52.305565</td>\n",
       "      <td>-10.016787</td>\n",
       "      <td>40.401790</td>\n",
       "      <td>-31.673523</td>\n",
       "      <td>95.932667</td>\n",
       "      <td>20.387663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571162</td>\n",
       "      <td>-0.773942</td>\n",
       "      <td>5.927902</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424206</td>\n",
       "      <td>0.851171</td>\n",
       "      <td>0.729696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.912128</td>\n",
       "      <td>3.186334</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>-2.263873</td>\n",
       "      <td>32.211659</td>\n",
       "      <td>7.872188</td>\n",
       "      <td>29.660602</td>\n",
       "      <td>9.790244</td>\n",
       "      <td>64.282235</td>\n",
       "      <td>52.942869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>-0.339467</td>\n",
       "      <td>5.015406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175598</td>\n",
       "      <td>0.863414</td>\n",
       "      <td>1.909411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.389432</td>\n",
       "      <td>12.846308</td>\n",
       "      <td>15.714182</td>\n",
       "      <td>1.935544</td>\n",
       "      <td>5.313678</td>\n",
       "      <td>-4.517069</td>\n",
       "      <td>-2.251007</td>\n",
       "      <td>1.656731</td>\n",
       "      <td>35.041365</td>\n",
       "      <td>21.823335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264328</td>\n",
       "      <td>0.760691</td>\n",
       "      <td>3.019532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335537</td>\n",
       "      <td>0.345069</td>\n",
       "      <td>1.931279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.532329</td>\n",
       "      <td>-1.060811</td>\n",
       "      <td>2.501133</td>\n",
       "      <td>-3.625128</td>\n",
       "      <td>11.348225</td>\n",
       "      <td>-2.284085</td>\n",
       "      <td>-6.326895</td>\n",
       "      <td>-9.138714</td>\n",
       "      <td>102.977036</td>\n",
       "      <td>-25.022726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915685</td>\n",
       "      <td>0.772376</td>\n",
       "      <td>2.650678</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585149</td>\n",
       "      <td>0.416681</td>\n",
       "      <td>0.579716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>77.929050</td>\n",
       "      <td>28.100279</td>\n",
       "      <td>42.522791</td>\n",
       "      <td>58.950012</td>\n",
       "      <td>72.891011</td>\n",
       "      <td>8.689332</td>\n",
       "      <td>15.745896</td>\n",
       "      <td>70.637400</td>\n",
       "      <td>68.260095</td>\n",
       "      <td>25.125369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066140</td>\n",
       "      <td>0.534360</td>\n",
       "      <td>3.057700</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162284</td>\n",
       "      <td>1.231858</td>\n",
       "      <td>0.971241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pi_E_1    pi_px_1    pi_py_1    pi_pz_1     pi_E_2    pi_px_2  \\\n",
       "entry                                                                     \n",
       "4      26.184192   5.249920 -12.394966 -22.458754  52.305565 -10.016787   \n",
       "15      3.912128   3.186334   0.086207  -2.263873  32.211659   7.872188   \n",
       "26     20.389432  12.846308  15.714182   1.935544   5.313678  -4.517069   \n",
       "39      4.532329  -1.060811   2.501133  -3.625128  11.348225  -2.284085   \n",
       "55     77.929050  28.100279  42.522791  58.950012  72.891011   8.689332   \n",
       "\n",
       "         pi_py_2    pi_pz_2     pi0_E_1   pi0_px_1  ...     y_1_1     y_1_2  \\\n",
       "entry                                               ...                       \n",
       "4      40.401790 -31.673523   95.932667  20.387663  ...  0.571162 -0.773942   \n",
       "15     29.660602   9.790244   64.282235  52.942869  ...  0.885265 -0.339467   \n",
       "26     -2.251007   1.656731   35.041365  21.823335  ...  0.264328  0.760691   \n",
       "39     -6.326895  -9.138714  102.977036 -25.022726  ...  0.915685  0.772376   \n",
       "55     15.745896  70.637400   68.260095  25.125369  ... -0.066140  0.534360   \n",
       "\n",
       "       aco_angle_1  tau_decay_mode_1  tau_decay_mode_2  mva_dm_1  mva_dm_2  \\\n",
       "entry                                                                        \n",
       "4         5.927902                 1                 1         1         1   \n",
       "15        5.015406                 1                 1         1         1   \n",
       "26        3.019532                 1                 1         1         1   \n",
       "39        2.650678                 1                 1         1         1   \n",
       "55        3.057700                 1                 1         1         1   \n",
       "\n",
       "           rand  wt_cp_ps  wt_cp_sm  \n",
       "entry                                \n",
       "4      0.424206  0.851171  0.729696  \n",
       "15     0.175598  0.863414  1.909411  \n",
       "26     0.335537  0.345069  1.931279  \n",
       "39     0.585149  0.416681  0.579716  \n",
       "55     0.162284  1.231858  0.971241  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try and do everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The different 4 vectors, (E,px,py,pz)\n",
    "pi_1=np.array([df4[\"pi_E_1\"],df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"]])\n",
    "pi_2=np.array([df4[\"pi_E_2\"],df4[\"pi_px_2\"],df4[\"pi_py_2\"],df4[\"pi_pz_2\"]])\n",
    "\n",
    "pi0_1=np.array([df4[\"pi0_E_1\"],df4[\"pi0_px_1\"],df4[\"pi0_py_1\"],df4[\"pi0_pz_1\"]])\n",
    "pi0_2=np.array([df4[\"pi0_E_2\"],df4[\"pi0_px_2\"],df4[\"pi0_py_2\"],df4[\"pi0_pz_2\"]])\n",
    "\n",
    "\n",
    "# Create x and y tensors\n",
    "#x = tf.convert_to_tensor(np.array(df4[momenta_features],dtype=np.float32), dtype=np.float32)\n",
    "#x = tf.constant(np.array(df4[momenta_features],np.float32),dtype=\"float32\")\n",
    "\n",
    "# Reshape for LBN\n",
    "#x = tf.reshape(x, (x.shape[0], 4, 4)) #have I reshaped anything really ??\n",
    "#print(x)\n",
    "\n",
    "# Normalise input:\n",
    "#x = (x - tf.math.reduce_mean(x,axis = 0))/tf.math.reduce_std(x, axis=0)\n",
    "\n",
    "#y = tf.convert_to_tensor(np.array(df4[[\"aco_angle_1\"]],dtype=np.float32), dtype=np.float32) #this is the target\n",
    "#y = tf.constant(np.array(df4[[\"aco_angle_1\"]],dtype=np.float32),dtype=\"float32\")\n",
    "\n",
    "#print(y,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               5100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 95,765\n",
      "Trainable params: 95,733\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Now we will try and use lbn to get aco_angle_1 from the 'raw data'\n",
    "\n",
    "# start a sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# add the LBN layer\n",
    "input_shape = (4, 4) #what input shape do we want ?\n",
    "\n",
    "#we have 4 particles,\n",
    "output = [\"E\", \"px\",\"py\",\"pz\",\"pt\",\"pair_dy\"]  #all the output we want  \n",
    "\n",
    "\n",
    "#define NN model and compile\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten( input_shape=(4,4)),\n",
    "    #LBNLayer((4, 4), 11, boost_mode=LBN.PAIRS, features=LBN_output_features),\n",
    "    tf.keras.layers.BatchNormalization(),   #what does this do ?\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1021 15:35:50.807878 140322321758016 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9e9a400c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9e9a400c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3180/3183 [============================>.] - ETA: 0s - loss: 3.4361 - mse: 3.4361- ETA: 0s - loss: 3.4360 - mse: 3.4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1021 15:36:19.260813 140322321758016 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9e8c03f7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9e8c03f7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3183/3183 [==============================] - 30s 10ms/step - loss: 3.4367 - mse: 3.4367 - val_loss: 3.3508 - val_mse: 3.3508\n",
      "Epoch 2/50\n",
      "3183/3183 [==============================] - 27s 8ms/step - loss: 3.3501 - mse: 3.3501 - val_loss: 3.3384 - val_mse: 3.3384\n",
      "Epoch 3/50\n",
      "3183/3183 [==============================] - 26s 8ms/step - loss: 3.3312 - mse: 3.3312 - val_loss: 3.3478 - val_mse: 3.3478\n",
      "Epoch 4/50\n",
      "3183/3183 [==============================] - 15s 5ms/step - loss: 3.3224 - mse: 3.3224 - val_loss: 3.3554 - val_mse: 3.3554\n",
      "Epoch 5/50\n",
      "3183/3183 [==============================] - 19s 6ms/step - loss: 3.3183 - mse: 3.3183 - val_loss: 3.3715 - val_mse: 3.3715\n",
      "Epoch 6/50\n",
      "3183/3183 [==============================] - 23s 7ms/step - loss: 3.3148 - mse: 3.3148 - val_loss: 3.3187 - val_mse: 3.3187\n",
      "Epoch 7/50\n",
      "3183/3183 [==============================] - 30s 10ms/step - loss: 3.3124 - mse: 3.3124 - val_loss: 3.3069 - val_mse: 3.3069\n",
      "Epoch 8/50\n",
      "3183/3183 [==============================] - 21s 6ms/step - loss: 3.3090 - mse: 3.3090 - val_loss: 3.3066 - val_mse: 3.3066\n",
      "Epoch 9/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3064 - mse: 3.3064 - val_loss: 3.3057 - val_mse: 3.3057\n",
      "Epoch 10/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3060 - mse: 3.3060 - val_loss: 3.3042 - val_mse: 3.3042\n",
      "Epoch 11/50\n",
      "3183/3183 [==============================] - 17s 5ms/step - loss: 3.3045 - mse: 3.3045 - val_loss: 3.3096 - val_mse: 3.3096\n",
      "Epoch 12/50\n",
      "3183/3183 [==============================] - 17s 5ms/step - loss: 3.3049 - mse: 3.3049 - val_loss: 3.3242 - val_mse: 3.3242\n",
      "Epoch 13/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3051 - mse: 3.3051 - val_loss: 3.3028 - val_mse: 3.3028\n",
      "Epoch 14/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3035 - mse: 3.3035 - val_loss: 3.3058 - val_mse: 3.3058\n",
      "Epoch 15/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3023 - mse: 3.3023 - val_loss: 3.3104 - val_mse: 3.3104\n",
      "Epoch 16/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3006 - mse: 3.3006 - val_loss: 3.3036 - val_mse: 3.3036\n",
      "Epoch 17/50\n",
      "3183/3183 [==============================] - 17s 5ms/step - loss: 3.3006 - mse: 3.3006 - val_loss: 3.3062 - val_mse: 3.3062\n",
      "Epoch 18/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3018 - mse: 3.3018 - val_loss: 3.3098 - val_mse: 3.3098\n",
      "Epoch 19/50\n",
      "3183/3183 [==============================] - 16s 5ms/step - loss: 3.3011 - mse: 3.3011 - val_loss: 3.3075 - val_mse: 3.3075\n",
      "Epoch 20/50\n",
      "3183/3183 [==============================] - 17s 5ms/step - loss: 3.3002 - mse: 3.3002 - val_loss: 3.3185 - val_mse: 3.3185\n",
      "Epoch 21/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3001 - mse: 3.3001 - val_loss: 3.3157 - val_mse: 3.3157\n",
      "Epoch 22/50\n",
      "3183/3183 [==============================] - 18s 6ms/step - loss: 3.3003 - mse: 3.3003 - val_loss: 3.3081 - val_mse: 3.3081\n",
      "Epoch 23/50\n",
      "3065/3183 [===========================>..] - ETA: 0s - loss: 3.2982 - mse: 3.2982"
     ]
    }
   ],
   "source": [
    "#Next run it\n",
    "# compile the model (we have to pass a loss or it won't compile)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError() #try with this function but could do with loss=\"categorical_crossentropy\" instead\n",
    "model.compile(loss=loss_fn,optimizer='adam', metrics=['mse'])\n",
    "\n",
    "\n",
    "x=np.array(df4[momenta_features],dtype=np.float32)\n",
    "x=np.reshape(x,(len(x),4,4))    #could there be an issue with how x and y are defined as in the reshaping of x?\n",
    "y=np.array(df4[[\"aco_angle_1\"]],dtype=np.float32)\n",
    "\n",
    "#train model\n",
    "history = model.fit(x, y, validation_split=0.3, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot traning\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "plt.title(\"Loss on Iteration\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#mean square error is how bad it is... pi is I'll guess the middle each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Try and let the program do half and us the other half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user pylorentz\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Vector4\n",
    "from pylorentz import Position4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some geometrical functions\n",
    "\n",
    "def cross_product(vector3_1,vector3_2):\n",
    "    if len(vector3_1)!=3 or len(vector3_1)!=3:\n",
    "        print('These are not 3D arrays !')\n",
    "    x_perp_vector=vector3_1[1]*vector3_2[2]-vector3_1[2]*vector3_2[1]\n",
    "    y_perp_vector=vector3_1[2]*vector3_2[0]-vector3_1[0]*vector3_2[2]\n",
    "    z_perp_vector=vector3_1[0]*vector3_2[1]-vector3_1[1]*vector3_2[0]\n",
    "    return np.array([x_perp_vector,y_perp_vector,z_perp_vector])\n",
    "\n",
    "def dot_product(vector1,vector2):\n",
    "    if len(vector1)!=len(vector2):\n",
    "        raise Arrays_of_different_size\n",
    "    prod=0\n",
    "    for i in range(len(vector1)):\n",
    "        prod=prod+vector1[i]*vector2[i]\n",
    "    return prod\n",
    "\n",
    "\n",
    "def norm(vector):\n",
    "    if len(vector)!=3:\n",
    "        print('This is only for a 3d vector')\n",
    "    return np.sqrt(vector[0]**2+vector[1]**2+vector[2]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charged and neutral pion momenta\n",
    "pi_1_4Mom=Momentum4(df4[\"pi_E_1\"],df4[\"pi_px_1\"],df4[\"pi_py_1\"],df4[\"pi_pz_1\"])\n",
    "pi_2_4Mom=Momentum4(df4[\"pi_E_2\"],df4[\"pi_px_2\"],df4[\"pi_py_2\"],df4[\"pi_pz_2\"])\n",
    "\n",
    "#Same for the pi0\n",
    "pi0_1_4Mom=Momentum4(df4[\"pi0_E_1\"],df4[\"pi0_px_1\"],df4[\"pi0_py_1\"],df4[\"pi0_pz_1\"])\n",
    "pi0_2_4Mom=Momentum4(df4[\"pi0_E_2\"],df4[\"pi0_px_2\"],df4[\"pi0_py_2\"],df4[\"pi0_pz_2\"])\n",
    "\n",
    "#This is the COM frame of the two charged pions w.r.t. which we'll boost\n",
    "ref_COM_4Mom=Momentum4(pi_1_4Mom+pi_2_4Mom)\n",
    "\n",
    "energies=[df4[\"pi_E_1\"],df4[\"pi_E_2\"],df4[\"pi0_E_1\"],df4[\"pi0_E_2\"]]\n",
    "\n",
    "\n",
    "#Lorentz boost everything in the ZMF of the two charged pions\n",
    "pi0_1_4Mom_star=pi0_1_4Mom.boost_particle(-ref_COM_4Mom)\n",
    "pi0_2_4Mom_star=pi0_2_4Mom.boost_particle(-ref_COM_4Mom)\n",
    "\n",
    "#Lorentz boost everything in the ZMF of the two neutral pions\n",
    "pi_1_4Mom_star=pi_1_4Mom.boost_particle(-ref_COM_4Mom)\n",
    "pi_2_4Mom_star=pi_2_4Mom.boost_particle(-ref_COM_4Mom)\n",
    "\n",
    "\n",
    "#calculating the perpependicular component\n",
    "pi0_1_3Mom_star_perp=cross_product(pi0_1_4Mom_star[1:],pi_1_4Mom_star[1:])\n",
    "pi0_2_3Mom_star_perp=cross_product(pi0_2_4Mom_star[1:],pi_2_4Mom_star[1:])\n",
    "\n",
    "#Now normalise:\n",
    "pi0_1_3Mom_star_perp=pi0_1_3Mom_star_perp/norm(pi0_1_3Mom_star_perp)\n",
    "pi0_2_3Mom_star_perp=pi0_2_3Mom_star_perp/norm(pi0_2_3Mom_star_perp)\n",
    "\n",
    "pi0_1_4Mom_star_perp=[pi0_1_4Mom_star[0],*pi0_1_3Mom_star_perp]\n",
    "pi0_2_4Mom_star_perp=[pi0_1_4Mom_star[0],*pi0_2_3Mom_star_perp]\n",
    "\n",
    "#Calculating phi_star\n",
    "phi_CP=np.arccos(dot_product(pi0_1_3Mom_star_perp,pi0_2_3Mom_star_perp))\n",
    "\n",
    "#The energy ratios\n",
    "y_T = np.array(df4['y_1_1']*df4['y_1_2'])\n",
    "\n",
    "#The O variable\n",
    "cross=np.array(np.cross(pi0_1_3Mom_star_perp.transpose(),pi0_2_3Mom_star_perp.transpose()).transpose())\n",
    "bigO=dot_product(pi_2_4Mom_star[1:],cross)\n",
    "\n",
    "\n",
    "\n",
    "#perform the shift w.r.t. O* sign\n",
    "#phi_CP=np.where(bigO>=0, 2*np.pi-phi_CP, phi_CP)#, phi_CP)\n",
    "\n",
    "\n",
    "#additionnal shift that needs to be done do see differences between odd and even scenarios, with y=Energy ratios\n",
    "#phi_CP=np.where(y_T>=0, np.where(phi_CP<np.pi, phi_CP+np.pi, phi_CP-np.pi), phi_CP)\n",
    "\n",
    "#Here we have the right datasets after the boosting, let's try and get a NN to output aco_angle_1 from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to be used in training\n",
    "\n",
    "y=np.array(df4[\"aco_angle_1\"],dtype=\"float32\")\n",
    "#y=np.reshape(y,(len(y[0]),len(y)))\n",
    "\n",
    "#x=np.array([*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, np.sign(y_T),*pi_2_4Mom_star[1:]],dtype=\"float32\").transpose()\n",
    "x=np.array([*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *pi_2_4Mom_star,*pi_1_4Mom_star],dtype=\"float32\").transpose()\n",
    "#x=np.reshape(x,(len(x),3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will try and use lbn to get aco_angle_1 from the 'raw data'\n",
    "\n",
    "# start a sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#we have 4 particles,\n",
    "#output = [\"E\", \"px\",\"py\",\"pz\",\"pt\",\"pair_dy\"]  #all the output we want  \n",
    "\n",
    "\n",
    "#define NN model and compile, try with less layers with less nodes (all other inout features bring noise)\n",
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Flatten(input_shape=(1,)),\n",
    "    #tf.keras.layers.BatchNormalization(),   #what does this do : normlise all features, have 1std and mean 0?   \n",
    "    tf.keras.layers.Dense(10, activation='relu',input_shape=(len(x[0]),)), \n",
    "    tf.keras.layers.Dense(10, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='relu'), \n",
    "    #tf.keras.layers.Dense(8, activation='relu'), \n",
    "    #tf.keras.layers.Dense(30, activation='relu'),\n",
    "    #tf.keras.layers.Dense(300, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "history = model.fit(x, y, validation_split=0.3, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each time giving the loss after 10 epochs\n",
    "\n",
    "#tried running with phi_CP(before shift), bi0 and y_T, got 3.36 - bad\n",
    "#tried running with phi_CP(after shift) - good\n",
    "#tried running with phi_CP(after shift), b0 - bad\n",
    "#tried running with phi_CP(after shift), phi_CP(after shift) - bad\n",
    "#tried running with phi_CP(after shift), phi_CP(after shift) - with y is 2d - good\n",
    "#tried running with phi_CP(after shift), bO -  with y is 2d - medium:1.05\n",
    "#tried running with phi_CP(after shift b0, before shift y_T), y_T -  with y is 2d - overfitting\n",
    "#tried running with phi_CP(after shift b0, before shift y_T), sign(y_T) -  bad\n",
    "#tried running with phi_CP(after shift b0, before shift y_T), sign(y_T) - 3 nodes, 3 nodes -  bad\n",
    "#tried running with phi_CP(after shift b0, before shift y_T), sign(y_T) - 3 nodes -  bad\n",
    "\n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), sign(y_T) - 8 nodes -  great:0.2403   \n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), y_T - 8 nodes -  good:0.6884 #could carry on longer\n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), y_T - 15 nodes -  good:0.6542 #could carry on longer\n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), y_T - 8 nodes and 8 nodes (relu)-  great:0.0611\n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), y_T - 8 nodes and 8 nodes and 8 nodes -  good:0.0928\n",
    "#tried running with phi_CP(after shift b0.T, before shift y_T), y_T - 8 nodes and 8 nodes (sigmoid)-  kinda bad:0.7547\n",
    "\n",
    "#tried running with phi_CP(before any shift), y_T,bi0 - 8 nodes and 8 nodes (relu)-  impressive:0.1923 #could carry on\n",
    "#tried running with phi_CP(before any shift), y_T,bi0 - 10 nodes and 10 nodes (relu)-  better:0.1327\n",
    "#tried running with phi_CP(before any shift), y_T,bi0 - 15 nodes and 15 nodes (relu)-  worse:0.2187 #noise starts to creep in I think\n",
    "\n",
    "#tried running with*pi0_1_3Mom_star_perp,*pi0_2_3Mom_star_perp - 10 nodes and 10 nodes (relu)- y= phi_CP - great:0.0038\n",
    "#tried running with*pi0_1_3Mom_star_perp,*pi0_2_3Mom_star_perp,y_T,bigO - 10 nodes and 10 nodes (relu)- y= angle - good:0.7817\n",
    "#tried running with*pi0_1_3Mom_star_perp,*pi0_2_3Mom_star_perp,np.sign(y_T),np.sign(bigO) - 10 nodes and 10 nodes (relu)- y= angle - great:0.0405\n",
    "#tried running with*pi0_1_4Mom_star_perp,*pi0_2_4Mom_star_perp,np.sign(y_T),np.sign(bigO) - 10 nodes and 10 nodes (relu)- y= angle - still great:0.0631\n",
    "#tried running with*pi0_1_4Mom_star_perp,*pi0_2_4Mom_star_perp,np.sign(y_T),*cross - 10 nodes and 10 nodes (relu)- y= angle - bad, because not included pi_2_4Mom_star\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, np.sign(y_T), *cross,*pi_2_4Mom_star[1:] - (10,10) - y=angle - ok: 1.1545\n",
    "\n",
    "#from now on, 20\n",
    "\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, np.sign(y_T),*pi_2_4Mom_star[1:] - (10,10) - y=angle - not good:2.1157\n",
    "\n",
    "# this is 'as low level' as we can go with bigO, try now to go low level on y_T\n",
    "\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *energies, bigO - (10,10) - y=angle - quite good:1.3131 \n",
    "#tried running with*pi0_2_3Mom_star_perp, *pi0_1_3Mom_star_perp, *energies, bigO - (10,10) - y=angle - better : 1.1867\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, y_T, bigO -(10,10) - y=angle - obv better : 0.3337\n",
    "\n",
    "#now try both modified:\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *energies,*pi_2_4Mom_star[1:] - (10,10) - y=angle - bad: 3.3020 \n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *pi_2_4Mom_star[1:],*pi_1_4Mom_star[1:] - (10,10) - y=angle - actually better: 3.1315\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *pi_2_4Mom_star[1:],*pi_1_4Mom_star[1:] - (10,10,10) - y=angle - still better:3.0340\n",
    "#which is really weird because we do not have the energies of the pi\n",
    "\n",
    "\n",
    "#tried running with*pi0_2_4Mom_star_perp, *pi0_1_4Mom_star_perp, *pi_2_4Mom_star,*pi_1_4Mom_star - (10,10,10) - y=angle - not much better:3.0302 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Could we load a specific pre-trained layer being taught about cross products on simpler data sets\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/losses/cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot traning\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "plt.title(\"Loss on Iteration\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It doesn't work very well, is it missing the value of y_T ?\n",
    "\n",
    "y_1=(-df4[\"pi_E_1\"]+df4[\"pi0_E_1\"])/(df4[\"pi_E_1\"]+df4[\"pi0_E_1\"]) #so yeah retrives it from the energy is possible\n",
    "y_2=(-df4[\"pi_E_2\"]+df4[\"pi0_E_2\"])/(df4[\"pi_E_2\"]+df4[\"pi0_E_2\"])\n",
    "\n",
    "plt.hist(y_2,alpha=0.5)\n",
    "plt.hist(df4[\"y_1_2\"],alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
